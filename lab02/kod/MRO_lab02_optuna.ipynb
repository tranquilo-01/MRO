{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5WY1LP3aUgdH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch.optim as optim\n",
    "from datetime import datetime, timedelta\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================= DEFINICJA SIECI ==========================================================\n",
    "\n",
    "class LeNet5CIFAR10(nn.Module):\n",
    "    def __init__(self, num_layers, layer_sizes, dropout_rate):\n",
    "        super(LeNet5CIFAR10, self).__init__()\n",
    "\n",
    "        # Validate input\n",
    "        if num_layers < 2 or num_layers > 10:\n",
    "            raise ValueError(\"num_layers must be between 2 and 10\")\n",
    "        if len(layer_sizes) != num_layers:\n",
    "            raise ValueError(\"layer_sizes length must match num_layers\")\n",
    "        \n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fcs = nn.ModuleList()  # Initialize as a list to hold the layers dynamically\n",
    "\n",
    "        # Define the first fully connected layer, input size matches flattened conv output\n",
    "        input_size = 16 * 5 * 5\n",
    "        self.fcs.append(nn.Linear(input_size, layer_sizes[0]))\n",
    "\n",
    "        # Define the intermediate layers based on `num_layers` and `layer_sizes`\n",
    "        for i in range(1, num_layers - 1):\n",
    "            self.fcs.append(nn.Linear(layer_sizes[i - 1], layer_sizes[i]))\n",
    "\n",
    "        # Output layer\n",
    "        self.fcs.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        # Apply fully connected layers with ReLU activations for all but last\n",
    "        for layer in self.fcs[:-1]:\n",
    "            out = F.relu(layer(out))\n",
    "\n",
    "        # Final layer (no activation to allow for softmax)\n",
    "        # x = self.fcs[-1](x)\n",
    "        return self.fcs[-1](out)\n",
    "\n",
    "        # Apply softmax for class probabilities\n",
    "        # return F.softmax(x, dim=1)\n",
    "\n",
    "        print(\"END FORWARD\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toSZlWpddOdp",
    "outputId": "d127080a-ac20-467c-ef13-5dbf55d116d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Podział danych treningowych na zbiór treningowy i walidacyjny (90% na trening, 10% na walidację)\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "def train_and_eval(learning_rate, num_layers, layer_sizes, batch_size, dropout_rate, weight_decay):\n",
    "  # Stworzenie DataLoaderów\n",
    "  train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "  val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "  net = LeNet5CIFAR10(num_layers, layer_sizes, dropout_rate).to(device)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "  start_time = datetime.datetime.now()\n",
    "  # Pętla treningowa\n",
    "  num_epochs = 15\n",
    "  for epoch in range(num_epochs):\n",
    "      net.train()\n",
    "      for inputs, labels in train_loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "          # Przepuszczenie danych przez sieć, obliczenie funkcji kosztu i wstecznej propagacji\n",
    "          outputs = net(inputs)\n",
    "          optimizer.zero_grad()\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "      print(f\"epoch {epoch+1}/{num_epochs}, elapsed time: {datetime.datetime.now() - start_time}\")\n",
    "\n",
    "\n",
    "  # Testowanie modelu - obliczenie accuracy\n",
    "  net.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for inputs, labels in test_loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = net(inputs)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = correct / total\n",
    "  return accuracy, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZetCdARfGY-",
    "outputId": "7ae68bc0-3722-4f3e-e946-84aa111f8f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/50, elapsed time: 0:00:23.351481\n",
      "epoch 2/50, elapsed time: 0:00:40.206933\n",
      "epoch 3/50, elapsed time: 0:00:57.859807\n",
      "epoch 4/50, elapsed time: 0:01:21.382910\n",
      "epoch 5/50, elapsed time: 0:01:39.525503\n",
      "epoch 6/50, elapsed time: 0:01:58.560174\n",
      "epoch 7/50, elapsed time: 0:02:14.607538\n",
      "epoch 8/50, elapsed time: 0:02:32.380440\n",
      "epoch 9/50, elapsed time: 0:02:49.580538\n",
      "epoch 10/50, elapsed time: 0:03:07.779247\n",
      "epoch 11/50, elapsed time: 0:03:24.970432\n",
      "epoch 12/50, elapsed time: 0:03:45.368555\n",
      "epoch 13/50, elapsed time: 0:04:01.913200\n",
      "epoch 14/50, elapsed time: 0:04:21.476160\n",
      "epoch 15/50, elapsed time: 0:04:42.909519\n",
      "epoch 16/50, elapsed time: 0:05:01.802934\n",
      "epoch 17/50, elapsed time: 0:05:19.404777\n",
      "epoch 18/50, elapsed time: 0:05:42.419396\n",
      "epoch 19/50, elapsed time: 0:05:59.729635\n",
      "epoch 20/50, elapsed time: 0:06:25.776633\n",
      "epoch 21/50, elapsed time: 0:06:45.446591\n",
      "epoch 22/50, elapsed time: 0:07:08.276091\n",
      "epoch 23/50, elapsed time: 0:07:24.816539\n",
      "epoch 24/50, elapsed time: 0:07:43.569060\n",
      "epoch 25/50, elapsed time: 0:08:00.990572\n",
      "epoch 26/50, elapsed time: 0:08:18.348502\n",
      "epoch 27/50, elapsed time: 0:08:37.891249\n",
      "epoch 28/50, elapsed time: 0:08:57.373293\n",
      "epoch 29/50, elapsed time: 0:09:17.819669\n",
      "epoch 30/50, elapsed time: 0:09:37.754080\n",
      "epoch 31/50, elapsed time: 0:09:57.268270\n",
      "epoch 32/50, elapsed time: 0:10:21.716876\n",
      "epoch 33/50, elapsed time: 0:14:23.938378\n",
      "epoch 34/50, elapsed time: 0:14:45.877062\n",
      "epoch 35/50, elapsed time: 0:17:39.673663\n",
      "epoch 36/50, elapsed time: 0:24:48.345619\n",
      "epoch 37/50, elapsed time: 0:31:51.645458\n",
      "epoch 38/50, elapsed time: 0:39:18.295794\n",
      "epoch 39/50, elapsed time: 0:45:54.471796\n",
      "epoch 40/50, elapsed time: 0:46:24.381883\n",
      "epoch 41/50, elapsed time: 0:46:52.576999\n",
      "epoch 42/50, elapsed time: 0:47:27.449928\n",
      "epoch 43/50, elapsed time: 0:47:52.736743\n",
      "epoch 44/50, elapsed time: 0:48:17.337368\n",
      "epoch 45/50, elapsed time: 0:48:38.724204\n",
      "epoch 46/50, elapsed time: 0:48:56.557370\n",
      "epoch 47/50, elapsed time: 0:49:23.287141\n",
      "epoch 48/50, elapsed time: 0:49:47.623473\n",
      "epoch 49/50, elapsed time: 0:50:23.218744\n",
      "epoch 50/50, elapsed time: 0:50:49.163416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6719"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_eval(0.00032612430218809, 2, [943, 10], 32, 0.0652566450453942, 1.35021744016308e-05)\n",
    "# Hyperparameters of trial number 84\n",
    "#   Learning Rate: 0.0003261243021880896\n",
    "#   Dropout Rate: 0.06525664504539422\n",
    "#   Weight Decay: 1.3502174401630838e-05\n",
    "#   Number of Layers: 2\n",
    "#   Batch Size: 32\n",
    "#   Layer Sizes: [943, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G98LNeTFA-zd",
    "outputId": "e2fe9c7a-887c-4076-9321-ea7e4617d280"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import datetime\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "ATmpzaPQXxjk",
    "outputId": "44f1b7b0-272e-4428-e1ce-caa65d7c50cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-01 02:18:47.721311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:18:49,694] A new study created in RDB with name: mro-kadet-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: mro-kadet-04\n",
      "A new study created in RDB with name: mro-kadet-04\n",
      "A new study created in RDB with name: mro-kadet-04\n",
      "A new study created in RDB with name: mro-kadet-04\n",
      "A new study created in RDB with name: mro-kadet-04\n",
      "A new study created in RDB with name: mro-kadet-04\n",
      "A new study created in RDB with name: mro-kadet-04\n",
      "Hyperparameters of trial number 0\n",
      "  Learning Rate: 0.002037847496967966\n",
      "  Dropout Rate: 0.4524419894039575\n",
      "  Weight Decay: 0.0003643103187585856\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [848, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:21:06,955] Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5717\n",
      "  Elapsed time: 0:02:17.149210\n",
      "\n",
      "\n",
      "\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 0 finished with value: 0.5717 and parameters: {'learning_rate': 0.002037847496967966, 'dropout_rate': 0.4524419894039575, 'weight_decay': 0.0003643103187585856, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 848.0}. Best is trial 0 with value: 0.5717.\n",
      "Hyperparameters of trial number 1\n",
      "  Learning Rate: 1.5052828106605899e-05\n",
      "  Dropout Rate: 0.4153954527819515\n",
      "  Weight Decay: 0.004258579382123662\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [473, 955, 685, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:22:42,034] Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.3983\n",
      "  Elapsed time: 0:01:34.941218\n",
      "\n",
      "\n",
      "\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Trial 1 finished with value: 0.3983 and parameters: {'learning_rate': 1.5052828106605899e-05, 'dropout_rate': 0.4153954527819515, 'weight_decay': 0.004258579382123662, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 473.0, 'layer-2-size': 955.0, 'layer-3-size': 685.0}. Best is trial 0 with value: 0.5717.\n",
      "Hyperparameters of trial number 2\n",
      "  Learning Rate: 0.0040150350386017625\n",
      "  Dropout Rate: 0.18432207655014676\n",
      "  Weight Decay: 4.428329909245621e-05\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [771, 619, 112, 853, 10]\n",
      "\n",
      "  Accuracy: 0.5948\n",
      "  Elapsed time: 0:18:12.615892\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:40:55,010] Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 2 finished with value: 0.5948 and parameters: {'learning_rate': 0.0040150350386017625, 'dropout_rate': 0.18432207655014676, 'weight_decay': 4.428329909245621e-05, 'num_layers': 5.0, 'batch_size': 16, 'layer-1-size': 771.0, 'layer-2-size': 619.0, 'layer-3-size': 112.0, 'layer-4-size': 853.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 3\n",
      "  Learning Rate: 2.4837524018200634e-05\n",
      "  Dropout Rate: 0.24572207723539796\n",
      "  Weight Decay: 0.0026280330577008793\n",
      "  Number of Layers: 6\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [459, 66, 570, 298, 537, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:42:47,415] Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.4048\n",
      "  Elapsed time: 0:01:52.302411\n",
      "\n",
      "\n",
      "\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 3 finished with value: 0.4048 and parameters: {'learning_rate': 2.4837524018200634e-05, 'dropout_rate': 0.24572207723539796, 'weight_decay': 0.0026280330577008793, 'num_layers': 6.0, 'batch_size': 256, 'layer-1-size': 459.0, 'layer-2-size': 66.0, 'layer-3-size': 570.0, 'layer-4-size': 298.0, 'layer-5-size': 537.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 4\n",
      "  Learning Rate: 0.0023251930561475434\n",
      "  Dropout Rate: 0.35313473760099856\n",
      "  Weight Decay: 0.00029650789651163647\n",
      "  Number of Layers: 10\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [701, 380, 570, 733, 1011, 253, 462, 263, 313, 10]\n",
      "\n",
      "  Accuracy: 0.1\n",
      "  Elapsed time: 0:10:35.843350\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:53:23,609] Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 4 finished with value: 0.1 and parameters: {'learning_rate': 0.0023251930561475434, 'dropout_rate': 0.35313473760099856, 'weight_decay': 0.00029650789651163647, 'num_layers': 10.0, 'batch_size': 128, 'layer-1-size': 701.0, 'layer-2-size': 380.0, 'layer-3-size': 570.0, 'layer-4-size': 733.0, 'layer-5-size': 1011.0, 'layer-6-size': 253.0, 'layer-7-size': 462.0, 'layer-8-size': 263.0, 'layer-9-size': 313.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 5\n",
      "  Learning Rate: 0.005121921919832015\n",
      "  Dropout Rate: 0.3175245370701787\n",
      "  Weight Decay: 0.004265640822086492\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [782, 438, 875, 939, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 02:55:17,849] Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.517\n",
      "  Elapsed time: 0:01:54.130938\n",
      "\n",
      "\n",
      "\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 5 finished with value: 0.517 and parameters: {'learning_rate': 0.005121921919832015, 'dropout_rate': 0.3175245370701787, 'weight_decay': 0.004265640822086492, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 782.0, 'layer-2-size': 438.0, 'layer-3-size': 875.0, 'layer-4-size': 939.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 6\n",
      "  Learning Rate: 2.9463036234049367e-05\n",
      "  Dropout Rate: 0.1571398004514994\n",
      "  Weight Decay: 0.0011895609211815964\n",
      "  Number of Layers: 6\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [200, 461, 358, 686, 316, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:07:45,620] Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5257\n",
      "  Elapsed time: 0:12:27.660941\n",
      "\n",
      "\n",
      "\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 6 finished with value: 0.5257 and parameters: {'learning_rate': 2.9463036234049367e-05, 'dropout_rate': 0.1571398004514994, 'weight_decay': 0.0011895609211815964, 'num_layers': 6.0, 'batch_size': 16, 'layer-1-size': 200.0, 'layer-2-size': 461.0, 'layer-3-size': 358.0, 'layer-4-size': 686.0, 'layer-5-size': 316.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 7\n",
      "  Learning Rate: 1.4320650566408862e-05\n",
      "  Dropout Rate: 0.3912383970063016\n",
      "  Weight Decay: 0.0070480225931611\n",
      "  Number of Layers: 7\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [246, 979, 71, 433, 68, 770, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:11:19,739] Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.2674\n",
      "  Elapsed time: 0:03:34.015701\n",
      "\n",
      "\n",
      "\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 7 finished with value: 0.2674 and parameters: {'learning_rate': 1.4320650566408862e-05, 'dropout_rate': 0.3912383970063016, 'weight_decay': 0.0070480225931611, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 246.0, 'layer-2-size': 979.0, 'layer-3-size': 71.0, 'layer-4-size': 433.0, 'layer-5-size': 68.0, 'layer-6-size': 770.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 8\n",
      "  Learning Rate: 0.0031580200157884618\n",
      "  Dropout Rate: 0.46580865759934686\n",
      "  Weight Decay: 0.0011398664218011387\n",
      "  Number of Layers: 8\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [211, 988, 355, 167, 974, 245, 604, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:20:17,833] Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.1\n",
      "  Elapsed time: 0:08:57.976770\n",
      "\n",
      "\n",
      "\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 8 finished with value: 0.1 and parameters: {'learning_rate': 0.0031580200157884618, 'dropout_rate': 0.46580865759934686, 'weight_decay': 0.0011398664218011387, 'num_layers': 8.0, 'batch_size': 128, 'layer-1-size': 211.0, 'layer-2-size': 988.0, 'layer-3-size': 355.0, 'layer-4-size': 167.0, 'layer-5-size': 974.0, 'layer-6-size': 245.0, 'layer-7-size': 604.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 9\n",
      "  Learning Rate: 0.0036455758911056613\n",
      "  Dropout Rate: 0.4423093690064197\n",
      "  Weight Decay: 1.920525307688304e-05\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [406, 196, 410, 671, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:23:15,258] Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5455\n",
      "  Elapsed time: 0:02:57.315804\n",
      "\n",
      "\n",
      "\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Trial 9 finished with value: 0.5455 and parameters: {'learning_rate': 0.0036455758911056613, 'dropout_rate': 0.4423093690064197, 'weight_decay': 1.920525307688304e-05, 'num_layers': 5.0, 'batch_size': 128, 'layer-1-size': 406.0, 'layer-2-size': 196.0, 'layer-3-size': 410.0, 'layer-4-size': 671.0}. Best is trial 2 with value: 0.5948.\n",
      "Hyperparameters of trial number 10\n",
      "  Learning Rate: 0.00045980874947719306\n",
      "  Dropout Rate: 0.003510536085684801\n",
      "  Weight Decay: 1.2936519321037755e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [965, 728, 10]\n",
      "\n",
      "  Accuracy: 0.6671\n",
      "  Elapsed time: 0:09:14.647059\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:32:30,261] Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Trial 10 finished with value: 0.6671 and parameters: {'learning_rate': 0.00045980874947719306, 'dropout_rate': 0.003510536085684801, 'weight_decay': 1.2936519321037755e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 965.0, 'layer-2-size': 728.0}. Best is trial 10 with value: 0.6671.\n",
      "Hyperparameters of trial number 11\n",
      "  Learning Rate: 0.000372815430213705\n",
      "  Dropout Rate: 0.00579564785383475\n",
      "  Weight Decay: 1.0015434526054381e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [963, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:38:14,379] Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6758\n",
      "  Elapsed time: 0:05:44.020672\n",
      "\n",
      "\n",
      "\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 11 finished with value: 0.6758 and parameters: {'learning_rate': 0.000372815430213705, 'dropout_rate': 0.00579564785383475, 'weight_decay': 1.0015434526054381e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 963.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 12\n",
      "  Learning Rate: 0.00028077134783044037\n",
      "  Dropout Rate: 0.011853053947394002\n",
      "  Weight Decay: 1.4519847968251891e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [996, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:41:42,344] Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6665\n",
      "  Elapsed time: 0:03:27.866107\n",
      "\n",
      "\n",
      "\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 12 finished with value: 0.6665 and parameters: {'learning_rate': 0.00028077134783044037, 'dropout_rate': 0.011853053947394002, 'weight_decay': 1.4519847968251891e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 13\n",
      "  Learning Rate: 0.00027836098202625335\n",
      "  Dropout Rate: 0.005543623624722529\n",
      "  Weight Decay: 5.736333634992279e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [1021, 725, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 03:50:59,544] Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6541\n",
      "  Elapsed time: 0:09:17.096336\n",
      "\n",
      "\n",
      "\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 13 finished with value: 0.6541 and parameters: {'learning_rate': 0.00027836098202625335, 'dropout_rate': 0.005543623624722529, 'weight_decay': 5.736333634992279e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1021.0, 'layer-2-size': 725.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 14\n",
      "  Learning Rate: 0.0008463642990398397\n",
      "  Dropout Rate: 0.07458282511495737\n",
      "  Weight Decay: 1.0916610371414134e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [909, 767, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 04:02:08,391] Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6519\n",
      "  Elapsed time: 0:11:08.747730\n",
      "\n",
      "\n",
      "\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 14 finished with value: 0.6519 and parameters: {'learning_rate': 0.0008463642990398397, 'dropout_rate': 0.07458282511495737, 'weight_decay': 1.0916610371414134e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 909.0, 'layer-2-size': 767.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 15\n",
      "  Learning Rate: 0.00015694246799470357\n",
      "  Dropout Rate: 0.10057886024888141\n",
      "  Weight Decay: 6.305620785741632e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [666, 808, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 04:09:03,846] Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6618\n",
      "  Elapsed time: 0:06:55.355204\n",
      "\n",
      "\n",
      "\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 15 finished with value: 0.6618 and parameters: {'learning_rate': 0.00015694246799470357, 'dropout_rate': 0.10057886024888141, 'weight_decay': 6.305620785741632e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 666.0, 'layer-2-size': 808.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 16\n",
      "  Learning Rate: 8.47805533976356e-05\n",
      "  Dropout Rate: 0.06831197676017338\n",
      "  Weight Decay: 0.0001185976421434834\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [914, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 04:14:48,922] Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6524\n",
      "  Elapsed time: 0:05:44.974089\n",
      "\n",
      "\n",
      "\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 16 finished with value: 0.6524 and parameters: {'learning_rate': 8.47805533976356e-05, 'dropout_rate': 0.06831197676017338, 'weight_decay': 0.0001185976421434834, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 914.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 17\n",
      "  Learning Rate: 0.0006577191397792962\n",
      "  Dropout Rate: 0.13862765189532697\n",
      "  Weight Decay: 2.7180628215005756e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [602, 669, 1009, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 04:22:42,324] Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6663\n",
      "  Elapsed time: 0:07:53.306152\n",
      "\n",
      "\n",
      "\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 17 finished with value: 0.6663 and parameters: {'learning_rate': 0.0006577191397792962, 'dropout_rate': 0.13862765189532697, 'weight_decay': 2.7180628215005756e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 602.0, 'layer-2-size': 669.0, 'layer-3-size': 1009.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 18\n",
      "  Learning Rate: 0.0008338236813741048\n",
      "  Dropout Rate: 0.24400484505967307\n",
      "  Weight Decay: 0.00014940865806055263\n",
      "  Number of Layers: 9\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [927, 259, 854, 106, 727, 1010, 1012, 946, 10]\n",
      "\n",
      "  Accuracy: 0.5613\n",
      "  Elapsed time: 0:45:04.293493\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:07:46,988] Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 18 finished with value: 0.5613 and parameters: {'learning_rate': 0.0008338236813741048, 'dropout_rate': 0.24400484505967307, 'weight_decay': 0.00014940865806055263, 'num_layers': 9.0, 'batch_size': 16, 'layer-1-size': 927.0, 'layer-2-size': 259.0, 'layer-3-size': 854.0, 'layer-4-size': 106.0, 'layer-5-size': 727.0, 'layer-6-size': 1010.0, 'layer-7-size': 1012.0, 'layer-8-size': 946.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 19\n",
      "  Learning Rate: 8.780464424378533e-05\n",
      "  Dropout Rate: 0.042808993363505535\n",
      "  Weight Decay: 2.9541531955791015e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [851, 547, 253, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:15:13,967] Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6431\n",
      "  Elapsed time: 0:07:26.856843\n",
      "\n",
      "\n",
      "\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 19 finished with value: 0.6431 and parameters: {'learning_rate': 8.780464424378533e-05, 'dropout_rate': 0.042808993363505535, 'weight_decay': 2.9541531955791015e-05, 'num_layers': 4.0, 'batch_size': 16, 'layer-1-size': 851.0, 'layer-2-size': 547.0, 'layer-3-size': 253.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 20\n",
      "  Learning Rate: 0.00847752848749094\n",
      "  Dropout Rate: 0.11501055554885511\n",
      "  Weight Decay: 1.0617621340163826e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [755, 860, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:24:10,419] Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5911\n",
      "  Elapsed time: 0:08:56.339323\n",
      "\n",
      "\n",
      "\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 20 finished with value: 0.5911 and parameters: {'learning_rate': 0.00847752848749094, 'dropout_rate': 0.11501055554885511, 'weight_decay': 1.0617621340163826e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 755.0, 'layer-2-size': 860.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 21\n",
      "  Learning Rate: 0.0004207270888194335\n",
      "  Dropout Rate: 0.003204087418187194\n",
      "  Weight Decay: 1.7605522607878486e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [981, 10]\n",
      "\n",
      "  Accuracy: 0.6707\n",
      "  Elapsed time: 0:03:40.688305\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:27:51,460] Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 21 finished with value: 0.6707 and parameters: {'learning_rate': 0.0004207270888194335, 'dropout_rate': 0.003204087418187194, 'weight_decay': 1.7605522607878486e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 22\n",
      "  Learning Rate: 0.00045485376428364003\n",
      "  Dropout Rate: 0.001531472746257063\n",
      "  Weight Decay: 2.401232986498215e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1018, 10]\n",
      "\n",
      "  Accuracy: 0.6691\n",
      "  Elapsed time: 0:03:35.222798\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:31:27,040] Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 22 finished with value: 0.6691 and parameters: {'learning_rate': 0.00045485376428364003, 'dropout_rate': 0.001531472746257063, 'weight_decay': 2.401232986498215e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1018.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 23\n",
      "  Learning Rate: 0.001524025304407997\n",
      "  Dropout Rate: 0.050886446774038904\n",
      "  Weight Decay: 2.6365806786281878e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1023, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:35:43,475] Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6675\n",
      "  Elapsed time: 0:04:16.328724\n",
      "\n",
      "\n",
      "\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 23 finished with value: 0.6675 and parameters: {'learning_rate': 0.001524025304407997, 'dropout_rate': 0.050886446774038904, 'weight_decay': 2.6365806786281878e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1023.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 24\n",
      "  Learning Rate: 0.00015109712525303732\n",
      "  Dropout Rate: 0.1889211240838718\n",
      "  Weight Decay: 9.496928962074784e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [857, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:39:13,061] Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6444\n",
      "  Elapsed time: 0:03:29.485457\n",
      "\n",
      "\n",
      "\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 24 finished with value: 0.6444 and parameters: {'learning_rate': 0.00015109712525303732, 'dropout_rate': 0.1889211240838718, 'weight_decay': 9.496928962074784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 857.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 25\n",
      "  Learning Rate: 0.0012752838930299138\n",
      "  Dropout Rate: 0.039853868125960035\n",
      "  Weight Decay: 3.365341610198015e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [945, 65, 688, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:45:25,144] Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6648\n",
      "  Elapsed time: 0:06:11.971015\n",
      "\n",
      "\n",
      "\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 25 finished with value: 0.6648 and parameters: {'learning_rate': 0.0012752838930299138, 'dropout_rate': 0.039853868125960035, 'weight_decay': 3.365341610198015e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 65.0, 'layer-3-size': 688.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 26\n",
      "  Learning Rate: 0.0004382833512484215\n",
      "  Dropout Rate: 0.09212396279430214\n",
      "  Weight Decay: 1.9356282028063327e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [840, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:49:11,800] Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6545\n",
      "  Elapsed time: 0:03:46.538897\n",
      "\n",
      "\n",
      "\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 26 finished with value: 0.6545 and parameters: {'learning_rate': 0.0004382833512484215, 'dropout_rate': 0.09212396279430214, 'weight_decay': 1.9356282028063327e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 840.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 27\n",
      "  Learning Rate: 0.00010121821538225418\n",
      "  Dropout Rate: 0.035361594646501425\n",
      "  Weight Decay: 5.771493076171894e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [575, 283, 10]\n",
      "\n",
      "  Accuracy: 0.6345\n",
      "  Elapsed time: 0:04:06.392376\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:53:18,543] Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 27 finished with value: 0.6345 and parameters: {'learning_rate': 0.00010121821538225418, 'dropout_rate': 0.035361594646501425, 'weight_decay': 5.771493076171894e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 575.0, 'layer-2-size': 283.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 28\n",
      "  Learning Rate: 0.00019922046448580874\n",
      "  Dropout Rate: 0.12323016295870964\n",
      "  Weight Decay: 1.668811268707968e-05\n",
      "  Number of Layers: 7\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [889, 564, 1015, 1014, 101, 520, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 05:58:19,830] Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6366\n",
      "  Elapsed time: 0:05:01.163401\n",
      "\n",
      "\n",
      "\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 28 finished with value: 0.6366 and parameters: {'learning_rate': 0.00019922046448580874, 'dropout_rate': 0.12323016295870964, 'weight_decay': 1.668811268707968e-05, 'num_layers': 7.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 564.0, 'layer-3-size': 1015.0, 'layer-4-size': 1014.0, 'layer-5-size': 101.0, 'layer-6-size': 520.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 29\n",
      "  Learning Rate: 4.9252854354271284e-05\n",
      "  Dropout Rate: 0.19423753682259998\n",
      "  Weight Decay: 0.0002462253133052416\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [810, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:00:33,027] Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5601\n",
      "  Elapsed time: 0:02:13.088023\n",
      "\n",
      "\n",
      "\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 29 finished with value: 0.5601 and parameters: {'learning_rate': 4.9252854354271284e-05, 'dropout_rate': 0.19423753682259998, 'weight_decay': 0.0002462253133052416, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 810.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 30\n",
      "  Learning Rate: 0.0004731286113249515\n",
      "  Dropout Rate: 0.291229116826151\n",
      "  Weight Decay: 0.0005461993067786311\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [959, 876, 204, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:10:12,439] Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6417\n",
      "  Elapsed time: 0:09:39.304619\n",
      "\n",
      "\n",
      "\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Trial 30 finished with value: 0.6417 and parameters: {'learning_rate': 0.0004731286113249515, 'dropout_rate': 0.291229116826151, 'weight_decay': 0.0005461993067786311, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 959.0, 'layer-2-size': 876.0, 'layer-3-size': 204.0}. Best is trial 11 with value: 0.6758.\n",
      "Hyperparameters of trial number 31\n",
      "  Learning Rate: 0.0011754797813607533\n",
      "  Dropout Rate: 0.05775606738269897\n",
      "  Weight Decay: 2.397212453188206e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1012, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:14:25,267] Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6763\n",
      "  Elapsed time: 0:04:12.722276\n",
      "\n",
      "\n",
      "\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 31 finished with value: 0.6763 and parameters: {'learning_rate': 0.0011754797813607533, 'dropout_rate': 0.05775606738269897, 'weight_decay': 2.397212453188206e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1012.0}. Best is trial 31 with value: 0.6763.\n",
      "Hyperparameters of trial number 32\n",
      "  Learning Rate: 0.001137503167658981\n",
      "  Dropout Rate: 0.0004336248439550591\n",
      "  Weight Decay: 3.8447711547413045e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [980, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:18:39,795] Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6568\n",
      "  Elapsed time: 0:04:14.412921\n",
      "\n",
      "\n",
      "\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Trial 32 finished with value: 0.6568 and parameters: {'learning_rate': 0.001137503167658981, 'dropout_rate': 0.0004336248439550591, 'weight_decay': 3.8447711547413045e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 31 with value: 0.6763.\n",
      "Hyperparameters of trial number 33\n",
      "  Learning Rate: 0.0006172350448972391\n",
      "  Dropout Rate: 0.07557763374020085\n",
      "  Weight Decay: 1.9961328309239425e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [889, 173, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:23:02,169] Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6867\n",
      "  Elapsed time: 0:04:22.260937\n",
      "\n",
      "\n",
      "\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 33 finished with value: 0.6867 and parameters: {'learning_rate': 0.0006172350448972391, 'dropout_rate': 0.07557763374020085, 'weight_decay': 1.9961328309239425e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 173.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 34\n",
      "  Learning Rate: 0.0017063391035668928\n",
      "  Dropout Rate: 0.07589728131725741\n",
      "  Weight Decay: 1.0142530983741175e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [722, 167, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:24:41,215] Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6863\n",
      "  Elapsed time: 0:01:38.931994\n",
      "\n",
      "\n",
      "\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 34 finished with value: 0.6863 and parameters: {'learning_rate': 0.0017063391035668928, 'dropout_rate': 0.07589728131725741, 'weight_decay': 1.0142530983741175e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 722.0, 'layer-2-size': 167.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 35\n",
      "  Learning Rate: 0.0014003714123093677\n",
      "  Dropout Rate: 0.07457091457077708\n",
      "  Weight Decay: 1.0065671807345296e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [734, 168, 755, 10]\n",
      "\n",
      "  Accuracy: 0.6521\n",
      "  Elapsed time: 0:01:43.289377\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:26:24,860] Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 35 finished with value: 0.6521 and parameters: {'learning_rate': 0.0014003714123093677, 'dropout_rate': 0.07457091457077708, 'weight_decay': 1.0065671807345296e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 734.0, 'layer-2-size': 168.0, 'layer-3-size': 755.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 36\n",
      "  Learning Rate: 0.002243492503003848\n",
      "  Dropout Rate: 0.1380966482322886\n",
      "  Weight Decay: 4.1758138331604664e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [804, 367, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:28:16,792] Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6642\n",
      "  Elapsed time: 0:01:51.826842\n",
      "\n",
      "\n",
      "\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 36 finished with value: 0.6642 and parameters: {'learning_rate': 0.002243492503003848, 'dropout_rate': 0.1380966482322886, 'weight_decay': 4.1758138331604664e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 804.0, 'layer-2-size': 367.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 37\n",
      "  Learning Rate: 0.006142487150638491\n",
      "  Dropout Rate: 0.15855209743184423\n",
      "  Weight Decay: 7.044879703484933e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [645, 151, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:29:57,619] Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6326\n",
      "  Elapsed time: 0:01:40.714052\n",
      "\n",
      "\n",
      "\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 37 finished with value: 0.6326 and parameters: {'learning_rate': 0.006142487150638491, 'dropout_rate': 0.15855209743184423, 'weight_decay': 7.044879703484933e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 645.0, 'layer-2-size': 151.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 38\n",
      "  Learning Rate: 0.002011934608831446\n",
      "  Dropout Rate: 0.22709825741949743\n",
      "  Weight Decay: 1.4547298998676409e-05\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [534, 310, 521, 478, 10]\n",
      "\n",
      "  Accuracy: 0.6365\n",
      "  Elapsed time: 0:01:55.396979\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:31:53,374] Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 38 finished with value: 0.6365 and parameters: {'learning_rate': 0.002011934608831446, 'dropout_rate': 0.22709825741949743, 'weight_decay': 1.4547298998676409e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 534.0, 'layer-2-size': 310.0, 'layer-3-size': 521.0, 'layer-4-size': 478.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 39\n",
      "  Learning Rate: 0.0009905818593972586\n",
      "  Dropout Rate: 0.08541445985419298\n",
      "  Weight Decay: 0.00022031570865656147\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [721, 215, 460, 318, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:33:52,463] Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6629\n",
      "  Elapsed time: 0:01:58.967452\n",
      "\n",
      "\n",
      "\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 39 finished with value: 0.6629 and parameters: {'learning_rate': 0.0009905818593972586, 'dropout_rate': 0.08541445985419298, 'weight_decay': 0.00022031570865656147, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 721.0, 'layer-2-size': 215.0, 'layer-3-size': 460.0, 'layer-4-size': 318.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 40\n",
      "  Learning Rate: 0.0005842314926119989\n",
      "  Dropout Rate: 0.05145379812206856\n",
      "  Weight Decay: 4.403256509901511e-05\n",
      "  Number of Layers: 6\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [336, 128, 245, 548, 578, 10]\n",
      "\n",
      "  Accuracy: 0.6578\n",
      "  Elapsed time: 0:02:44.317324\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:36:38,005] Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 40 finished with value: 0.6578 and parameters: {'learning_rate': 0.0005842314926119989, 'dropout_rate': 0.05145379812206856, 'weight_decay': 4.403256509901511e-05, 'num_layers': 6.0, 'batch_size': 128, 'layer-1-size': 336.0, 'layer-2-size': 128.0, 'layer-3-size': 245.0, 'layer-4-size': 548.0, 'layer-5-size': 578.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 41\n",
      "  Learning Rate: 0.00033380235515376985\n",
      "  Dropout Rate: 0.03329468901687204\n",
      "  Weight Decay: 1.9637066565973096e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [903, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:40:24,705] Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6722\n",
      "  Elapsed time: 0:03:46.581511\n",
      "\n",
      "\n",
      "\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 41 finished with value: 0.6722 and parameters: {'learning_rate': 0.00033380235515376985, 'dropout_rate': 0.03329468901687204, 'weight_decay': 1.9637066565973096e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 42\n",
      "  Learning Rate: 0.00023031954990810315\n",
      "  Dropout Rate: 0.02434789816921005\n",
      "  Weight Decay: 2.077887707186736e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [872, 429, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:43:20,653] Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6587\n",
      "  Elapsed time: 0:02:55.826085\n",
      "\n",
      "\n",
      "\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 42 finished with value: 0.6587 and parameters: {'learning_rate': 0.00023031954990810315, 'dropout_rate': 0.02434789816921005, 'weight_decay': 2.077887707186736e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 872.0, 'layer-2-size': 429.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 43\n",
      "  Learning Rate: 0.000692441042461214\n",
      "  Dropout Rate: 0.4941681442128072\n",
      "  Weight Decay: 1.3882954477214009e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [811, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:46:33,830] Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5992\n",
      "  Elapsed time: 0:03:13.073848\n",
      "\n",
      "\n",
      "\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 43 finished with value: 0.5992 and parameters: {'learning_rate': 0.000692441042461214, 'dropout_rate': 0.4941681442128072, 'weight_decay': 1.3882954477214009e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 811.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 44\n",
      "  Learning Rate: 0.0027339712467294003\n",
      "  Dropout Rate: 0.0615355434249262\n",
      "  Weight Decay: 1.0093593905236811e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [688, 337, 903, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:49:22,531] Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6475\n",
      "  Elapsed time: 0:02:48.594282\n",
      "\n",
      "\n",
      "\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 44 finished with value: 0.6475 and parameters: {'learning_rate': 0.0027339712467294003, 'dropout_rate': 0.0615355434249262, 'weight_decay': 1.0093593905236811e-05, 'num_layers': 4.0, 'batch_size': 128, 'layer-1-size': 688.0, 'layer-2-size': 337.0, 'layer-3-size': 903.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 45\n",
      "  Learning Rate: 0.0018014558852216173\n",
      "  Dropout Rate: 0.11902488653845067\n",
      "  Weight Decay: 2.3104484018658884e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [902, 510, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:51:04,433] Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6762\n",
      "  Elapsed time: 0:01:41.798769\n",
      "\n",
      "\n",
      "\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 45 finished with value: 0.6762 and parameters: {'learning_rate': 0.0018014558852216173, 'dropout_rate': 0.11902488653845067, 'weight_decay': 2.3104484018658884e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 902.0, 'layer-2-size': 510.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 46\n",
      "  Learning Rate: 0.001792087056197667\n",
      "  Dropout Rate: 0.10628887602763801\n",
      "  Weight Decay: 0.0005760453018197652\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [770, 616, 10]\n",
      "\n",
      "  Accuracy: 0.6605\n",
      "  Elapsed time: 0:01:56.628892\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:53:01,419] Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 46 finished with value: 0.6605 and parameters: {'learning_rate': 0.001792087056197667, 'dropout_rate': 0.10628887602763801, 'weight_decay': 0.0005760453018197652, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 770.0, 'layer-2-size': 616.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 47\n",
      "  Learning Rate: 0.004285351135246267\n",
      "  Dropout Rate: 0.15616180845245226\n",
      "  Weight Decay: 0.0029145342946009633\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [957, 248, 768, 250, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:54:47,462] Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5809\n",
      "  Elapsed time: 0:01:45.930293\n",
      "\n",
      "\n",
      "\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 47 finished with value: 0.5809 and parameters: {'learning_rate': 0.004285351135246267, 'dropout_rate': 0.15616180845245226, 'weight_decay': 0.0029145342946009633, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 957.0, 'layer-2-size': 248.0, 'layer-3-size': 768.0, 'layer-4-size': 250.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 48\n",
      "  Learning Rate: 0.0025362692645585017\n",
      "  Dropout Rate: 0.3604973462857489\n",
      "  Weight Decay: 3.313076560093183e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [841, 476, 157, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:56:38,361] Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.623\n",
      "  Elapsed time: 0:01:50.783782\n",
      "\n",
      "\n",
      "\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 48 finished with value: 0.623 and parameters: {'learning_rate': 0.0025362692645585017, 'dropout_rate': 0.3604973462857489, 'weight_decay': 3.313076560093183e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 841.0, 'layer-2-size': 476.0, 'layer-3-size': 157.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 49\n",
      "  Learning Rate: 0.0008089767032102294\n",
      "  Dropout Rate: 0.09758987934915392\n",
      "  Weight Decay: 8.890865149068458e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [928, 105, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 06:58:30,643] Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6628\n",
      "  Elapsed time: 0:01:52.171718\n",
      "\n",
      "\n",
      "\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 49 finished with value: 0.6628 and parameters: {'learning_rate': 0.0008089767032102294, 'dropout_rate': 0.09758987934915392, 'weight_decay': 8.890865149068458e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 928.0, 'layer-2-size': 105.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 50\n",
      "  Learning Rate: 0.0032206405519278974\n",
      "  Dropout Rate: 0.07105862830721461\n",
      "  Weight Decay: 0.007816738901484968\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [890, 502, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:10:21,354] Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.515\n",
      "  Elapsed time: 0:11:50.602683\n",
      "\n",
      "\n",
      "\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 50 finished with value: 0.515 and parameters: {'learning_rate': 0.0032206405519278974, 'dropout_rate': 0.07105862830721461, 'weight_decay': 0.007816738901484968, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 890.0, 'layer-2-size': 502.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 51\n",
      "  Learning Rate: 0.0003771961454364815\n",
      "  Dropout Rate: 0.022156870132737372\n",
      "  Weight Decay: 2.1010458130033046e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [902, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:13:57,063] Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6612\n",
      "  Elapsed time: 0:03:35.613602\n",
      "\n",
      "\n",
      "\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 51 finished with value: 0.6612 and parameters: {'learning_rate': 0.0003771961454364815, 'dropout_rate': 0.022156870132737372, 'weight_decay': 2.1010458130033046e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 52\n",
      "  Learning Rate: 0.0006020088602830411\n",
      "  Dropout Rate: 0.028650065188404378\n",
      "  Weight Decay: 1.383002970070521e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [990, 10]\n",
      "\n",
      "  Accuracy: 0.6595\n",
      "  Elapsed time: 0:01:44.957235\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:15:42,384] Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 52 finished with value: 0.6595 and parameters: {'learning_rate': 0.0006020088602830411, 'dropout_rate': 0.028650065188404378, 'weight_decay': 1.383002970070521e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 990.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 53\n",
      "  Learning Rate: 0.0003027994330383322\n",
      "  Dropout Rate: 0.05712907316629007\n",
      "  Weight Decay: 1.328371714000141e-05\n",
      "  Number of Layers: 10\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [926, 421, 644, 816, 349, 72, 154, 69, 1005, 10]\n",
      "\n",
      "  Accuracy: 0.6326\n",
      "  Elapsed time: 0:20:45.849757\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:36:28,599] Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 53 finished with value: 0.6326 and parameters: {'learning_rate': 0.0003027994330383322, 'dropout_rate': 0.05712907316629007, 'weight_decay': 1.328371714000141e-05, 'num_layers': 10.0, 'batch_size': 16, 'layer-1-size': 926.0, 'layer-2-size': 421.0, 'layer-3-size': 644.0, 'layer-4-size': 816.0, 'layer-5-size': 349.0, 'layer-6-size': 72.0, 'layer-7-size': 154.0, 'layer-8-size': 69.0, 'layer-9-size': 1005.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 54\n",
      "  Learning Rate: 1.0326847549286917e-05\n",
      "  Dropout Rate: 0.12821111821337036\n",
      "  Weight Decay: 2.3508096541625774e-05\n",
      "  Number of Layers: 7\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [796, 380, 305, 592, 793, 656, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:42:52,261] Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.4545\n",
      "  Elapsed time: 0:06:23.558483\n",
      "\n",
      "\n",
      "\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 54 finished with value: 0.4545 and parameters: {'learning_rate': 1.0326847549286917e-05, 'dropout_rate': 0.12821111821337036, 'weight_decay': 2.3508096541625774e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 796.0, 'layer-2-size': 380.0, 'layer-3-size': 305.0, 'layer-4-size': 592.0, 'layer-5-size': 793.0, 'layer-6-size': 656.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 55\n",
      "  Learning Rate: 0.000992722814106992\n",
      "  Dropout Rate: 0.07533462744655303\n",
      "  Weight Decay: 1.8308146416008954e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [460, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:44:49,474] Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6575\n",
      "  Elapsed time: 0:01:57.100963\n",
      "\n",
      "\n",
      "\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 55 finished with value: 0.6575 and parameters: {'learning_rate': 0.000992722814106992, 'dropout_rate': 0.07533462744655303, 'weight_decay': 1.8308146416008954e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 460.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 56\n",
      "  Learning Rate: 0.0017792673055144032\n",
      "  Dropout Rate: 0.02393223801478541\n",
      "  Weight Decay: 5.0485867082818125e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [874, 206, 10]\n",
      "\n",
      "  Accuracy: 0.67\n",
      "  Elapsed time: 0:11:00.869940\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 07:55:50,684] Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 56 finished with value: 0.67 and parameters: {'learning_rate': 0.0017792673055144032, 'dropout_rate': 0.02393223801478541, 'weight_decay': 5.0485867082818125e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 874.0, 'layer-2-size': 206.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 57\n",
      "  Learning Rate: 0.00020057358275240317\n",
      "  Dropout Rate: 0.0470389679783933\n",
      "  Weight Decay: 2.7599325286706308e-05\n",
      "  Number of Layers: 9\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [952, 633, 948, 68, 342, 1009, 1007, 1021, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:11:34,790] Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.614\n",
      "  Elapsed time: 0:15:44.000362\n",
      "\n",
      "\n",
      "\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 57 finished with value: 0.614 and parameters: {'learning_rate': 0.00020057358275240317, 'dropout_rate': 0.0470389679783933, 'weight_decay': 2.7599325286706308e-05, 'num_layers': 9.0, 'batch_size': 32, 'layer-1-size': 952.0, 'layer-2-size': 633.0, 'layer-3-size': 948.0, 'layer-4-size': 68.0, 'layer-5-size': 342.0, 'layer-6-size': 1009.0, 'layer-7-size': 1007.0, 'layer-8-size': 1021.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 58\n",
      "  Learning Rate: 0.00035662270591435265\n",
      "  Dropout Rate: 0.16674641796703127\n",
      "  Weight Decay: 0.0012594724406955263\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [835, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:14:27,141] Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6615\n",
      "  Elapsed time: 0:02:52.232862\n",
      "\n",
      "\n",
      "\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 58 finished with value: 0.6615 and parameters: {'learning_rate': 0.00035662270591435265, 'dropout_rate': 0.16674641796703127, 'weight_decay': 0.0012594724406955263, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 835.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 59\n",
      "  Learning Rate: 0.0005485654714414665\n",
      "  Dropout Rate: 0.2114966146622222\n",
      "  Weight Decay: 1.6151889871003628e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [993, 100, 459, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:19:35,065] Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6588\n",
      "  Elapsed time: 0:05:07.817544\n",
      "\n",
      "\n",
      "\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 59 finished with value: 0.6588 and parameters: {'learning_rate': 0.0005485654714414665, 'dropout_rate': 0.2114966146622222, 'weight_decay': 1.6151889871003628e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 993.0, 'layer-2-size': 100.0, 'layer-3-size': 459.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 60\n",
      "  Learning Rate: 0.0015343485984390824\n",
      "  Dropout Rate: 0.27891818979925054\n",
      "  Weight Decay: 3.442990210516654e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [756, 315, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:21:15,484] Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.646\n",
      "  Elapsed time: 0:01:40.313857\n",
      "\n",
      "\n",
      "\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 60 finished with value: 0.646 and parameters: {'learning_rate': 0.0015343485984390824, 'dropout_rate': 0.27891818979925054, 'weight_decay': 3.442990210516654e-05, 'num_layers': 3.0, 'batch_size': 256, 'layer-1-size': 756.0, 'layer-2-size': 315.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 61\n",
      "  Learning Rate: 0.0007657997626399531\n",
      "  Dropout Rate: 0.0855936976686622\n",
      "  Weight Decay: 1.2345251028838686e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1004, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:25:23,681] Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6722\n",
      "  Elapsed time: 0:04:08.089763\n",
      "\n",
      "\n",
      "\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 61 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007657997626399531, 'dropout_rate': 0.0855936976686622, 'weight_decay': 1.2345251028838686e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 62\n",
      "  Learning Rate: 0.0007848030392625229\n",
      "  Dropout Rate: 0.08795719916744363\n",
      "  Weight Decay: 1.273121459775006e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [997, 10]\n",
      "\n",
      "  Accuracy: 0.6829\n",
      "  Elapsed time: 0:04:08.704203\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:29:32,732] Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 62 finished with value: 0.6829 and parameters: {'learning_rate': 0.0007848030392625229, 'dropout_rate': 0.08795719916744363, 'weight_decay': 1.273121459775006e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 997.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 63\n",
      "  Learning Rate: 0.0011565486252608874\n",
      "  Dropout Rate: 0.10937081389982534\n",
      "  Weight Decay: 2.4173421529775173e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [922, 10]\n",
      "\n",
      "  Accuracy: 0.6684\n",
      "  Elapsed time: 0:03:59.005565\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:33:32,093] Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 63 finished with value: 0.6684 and parameters: {'learning_rate': 0.0011565486252608874, 'dropout_rate': 0.10937081389982534, 'weight_decay': 2.4173421529775173e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 922.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 64\n",
      "  Learning Rate: 0.0001346926513521721\n",
      "  Dropout Rate: 0.03859559530545598\n",
      "  Weight Decay: 1.7111994361135697e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [973, 931, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:37:54,226] Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6577\n",
      "  Elapsed time: 0:04:22.025366\n",
      "\n",
      "\n",
      "\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 64 finished with value: 0.6577 and parameters: {'learning_rate': 0.0001346926513521721, 'dropout_rate': 0.03859559530545598, 'weight_decay': 1.7111994361135697e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 973.0, 'layer-2-size': 931.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 65\n",
      "  Learning Rate: 0.00027183505431207535\n",
      "  Dropout Rate: 0.08773586376147885\n",
      "  Weight Decay: 1.1056520219288442e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1022, 10]\n",
      "\n",
      "  Accuracy: 0.6794\n",
      "  Elapsed time: 0:03:45.399285\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:41:39,984] Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 65 finished with value: 0.6794 and parameters: {'learning_rate': 0.00027183505431207535, 'dropout_rate': 0.08773586376147885, 'weight_decay': 1.1056520219288442e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1022.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 66\n",
      "  Learning Rate: 0.0010743962120730597\n",
      "  Dropout Rate: 0.14423563962845903\n",
      "  Weight Decay: 1.1199018469854089e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [1019, 240, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:49:49,762] Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6675\n",
      "  Elapsed time: 0:08:09.674460\n",
      "\n",
      "\n",
      "\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Trial 66 finished with value: 0.6675 and parameters: {'learning_rate': 0.0010743962120730597, 'dropout_rate': 0.14423563962845903, 'weight_decay': 1.1199018469854089e-05, 'num_layers': 3.0, 'batch_size': 16, 'layer-1-size': 1019.0, 'layer-2-size': 240.0}. Best is trial 33 with value: 0.6867.\n",
      "Hyperparameters of trial number 67\n",
      "  Learning Rate: 0.0005325557715692796\n",
      "  Dropout Rate: 0.12114918538117142\n",
      "  Weight Decay: 1.2603948168347459e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [950, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:52:38,632] Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6873\n",
      "  Elapsed time: 0:02:48.766323\n",
      "\n",
      "\n",
      "\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 67 finished with value: 0.6873 and parameters: {'learning_rate': 0.0005325557715692796, 'dropout_rate': 0.12114918538117142, 'weight_decay': 1.2603948168347459e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 950.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 68\n",
      "  Learning Rate: 0.0002489170888593606\n",
      "  Dropout Rate: 0.1189959863009204\n",
      "  Weight Decay: 1.2138533662988996e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [942, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 08:55:38,720] Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6666\n",
      "  Elapsed time: 0:02:59.978767\n",
      "\n",
      "\n",
      "\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 68 finished with value: 0.6666 and parameters: {'learning_rate': 0.0002489170888593606, 'dropout_rate': 0.1189959863009204, 'weight_decay': 1.2138533662988996e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 942.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 69\n",
      "  Learning Rate: 0.0008873016680395381\n",
      "  Dropout Rate: 0.09200302315858451\n",
      "  Weight Decay: 2.8890839646289698e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1024, 167, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:00:01,628] Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6596\n",
      "  Elapsed time: 0:04:22.792101\n",
      "\n",
      "\n",
      "\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 69 finished with value: 0.6596 and parameters: {'learning_rate': 0.0008873016680395381, 'dropout_rate': 0.09200302315858451, 'weight_decay': 2.8890839646289698e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1024.0, 'layer-2-size': 167.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 70\n",
      "  Learning Rate: 0.0005296293032544167\n",
      "  Dropout Rate: 0.18098464502730127\n",
      "  Weight Decay: 1.6699801117101954e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [983, 10]\n",
      "\n",
      "  Accuracy: 0.6764\n",
      "  Elapsed time: 0:03:00.861152\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:03:02,859] Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 70 finished with value: 0.6764 and parameters: {'learning_rate': 0.0005296293032544167, 'dropout_rate': 0.18098464502730127, 'weight_decay': 1.6699801117101954e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 71\n",
      "  Learning Rate: 0.0005112770688590098\n",
      "  Dropout Rate: 0.17257544075070122\n",
      "  Weight Decay: 1.5229094009120566e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [977, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:05:59,317] Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6789\n",
      "  Elapsed time: 0:02:56.351684\n",
      "\n",
      "\n",
      "\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 71 finished with value: 0.6789 and parameters: {'learning_rate': 0.0005112770688590098, 'dropout_rate': 0.17257544075070122, 'weight_decay': 1.5229094009120566e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 72\n",
      "  Learning Rate: 0.0005020586168757866\n",
      "  Dropout Rate: 0.17264547202292455\n",
      "  Weight Decay: 1.5225510236956451e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [978, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:08:51,510] Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6698\n",
      "  Elapsed time: 0:02:52.052589\n",
      "\n",
      "\n",
      "\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 72 finished with value: 0.6698 and parameters: {'learning_rate': 0.0005020586168757866, 'dropout_rate': 0.17264547202292455, 'weight_decay': 1.5225510236956451e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 978.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 73\n",
      "  Learning Rate: 0.0006906961705261196\n",
      "  Dropout Rate: 0.20188756002005484\n",
      "  Weight Decay: 1.219298258912503e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [986, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:11:37,521] Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6677\n",
      "  Elapsed time: 0:02:45.896501\n",
      "\n",
      "\n",
      "\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 73 finished with value: 0.6677 and parameters: {'learning_rate': 0.0006906961705261196, 'dropout_rate': 0.20188756002005484, 'weight_decay': 1.219298258912503e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 74\n",
      "  Learning Rate: 0.00044898152346085804\n",
      "  Dropout Rate: 0.1456683535465052\n",
      "  Weight Decay: 1.652589865003465e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [946, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:14:27,990] Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6767\n",
      "  Elapsed time: 0:02:50.360130\n",
      "\n",
      "\n",
      "\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 74 finished with value: 0.6767 and parameters: {'learning_rate': 0.00044898152346085804, 'dropout_rate': 0.1456683535465052, 'weight_decay': 1.652589865003465e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 946.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 75\n",
      "  Learning Rate: 0.0004320695407329017\n",
      "  Dropout Rate: 0.1471203123484351\n",
      "  Weight Decay: 1.6437399119717906e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [945, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:17:40,965] Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6723\n",
      "  Elapsed time: 0:03:12.823756\n",
      "\n",
      "\n",
      "\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 75 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004320695407329017, 'dropout_rate': 0.1471203123484351, 'weight_decay': 1.6437399119717906e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 76\n",
      "  Learning Rate: 0.0005373344805803809\n",
      "  Dropout Rate: 0.18040006437709222\n",
      "  Weight Decay: 1.2019702750737681e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [623, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:20:39,797] Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6614\n",
      "  Elapsed time: 0:02:58.727159\n",
      "\n",
      "\n",
      "\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 76 finished with value: 0.6614 and parameters: {'learning_rate': 0.0005373344805803809, 'dropout_rate': 0.18040006437709222, 'weight_decay': 1.2019702750737681e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 623.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 77\n",
      "  Learning Rate: 0.0002816176777957579\n",
      "  Dropout Rate: 0.13186984348723388\n",
      "  Weight Decay: 1.032331768916535e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [520, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:23:25,959] Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6554\n",
      "  Elapsed time: 0:02:46.049413\n",
      "\n",
      "\n",
      "\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 77 finished with value: 0.6554 and parameters: {'learning_rate': 0.0002816176777957579, 'dropout_rate': 0.13186984348723388, 'weight_decay': 1.032331768916535e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 520.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 78\n",
      "  Learning Rate: 0.00017873123731866253\n",
      "  Dropout Rate: 0.21090993972235816\n",
      "  Weight Decay: 1.9367826037848016e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [871, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:26:16,651] Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6491\n",
      "  Elapsed time: 0:02:50.586566\n",
      "\n",
      "\n",
      "\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 78 finished with value: 0.6491 and parameters: {'learning_rate': 0.00017873123731866253, 'dropout_rate': 0.21090993972235816, 'weight_decay': 1.9367826037848016e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 871.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 79\n",
      "  Learning Rate: 0.00038452429522372293\n",
      "  Dropout Rate: 0.22972522726696085\n",
      "  Weight Decay: 1.4713823653685313e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [966, 584, 10]\n",
      "\n",
      "  Accuracy: 0.6611\n",
      "  Elapsed time: 0:03:40.412425\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:29:57,433] Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 79 finished with value: 0.6611 and parameters: {'learning_rate': 0.00038452429522372293, 'dropout_rate': 0.22972522726696085, 'weight_decay': 1.4713823653685313e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 966.0, 'layer-2-size': 584.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 80\n",
      "  Learning Rate: 0.0006494087167274919\n",
      "  Dropout Rate: 0.10223323817295524\n",
      "  Weight Decay: 2.9997081035297265e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [378, 678, 10]\n",
      "\n",
      "  Accuracy: 0.6725\n",
      "  Elapsed time: 0:03:46.650747\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:33:44,445] Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 80 finished with value: 0.6725 and parameters: {'learning_rate': 0.0006494087167274919, 'dropout_rate': 0.10223323817295524, 'weight_decay': 2.9997081035297265e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 378.0, 'layer-2-size': 678.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 81\n",
      "  Learning Rate: 0.001278081697295865\n",
      "  Dropout Rate: 0.08045004742396406\n",
      "  Weight Decay: 2.1111137105873894e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [149, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:36:17,477] Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6564\n",
      "  Elapsed time: 0:02:32.918626\n",
      "\n",
      "\n",
      "\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 81 finished with value: 0.6564 and parameters: {'learning_rate': 0.001278081697295865, 'dropout_rate': 0.08045004742396406, 'weight_decay': 2.1111137105873894e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 149.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 82\n",
      "  Learning Rate: 0.0009147781237949832\n",
      "  Dropout Rate: 0.06004689534845842\n",
      "  Weight Decay: 1.6893193886162624e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1004, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:39:24,032] Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6782\n",
      "  Elapsed time: 0:03:06.459532\n",
      "\n",
      "\n",
      "\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 82 finished with value: 0.6782 and parameters: {'learning_rate': 0.0009147781237949832, 'dropout_rate': 0.06004689534845842, 'weight_decay': 1.6893193886162624e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1004.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 83\n",
      "  Learning Rate: 0.0008181505099121094\n",
      "  Dropout Rate: 0.14402888909545086\n",
      "  Weight Decay: 1.6051767554093898e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1000, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:42:21,705] Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6723\n",
      "  Elapsed time: 0:02:57.582344\n",
      "\n",
      "\n",
      "\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Trial 83 finished with value: 0.6723 and parameters: {'learning_rate': 0.0008181505099121094, 'dropout_rate': 0.14402888909545086, 'weight_decay': 1.6051767554093898e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1000.0}. Best is trial 67 with value: 0.6873.\n",
      "Hyperparameters of trial number 84\n",
      "  Learning Rate: 0.0003261243021880896\n",
      "  Dropout Rate: 0.06525664504539422\n",
      "  Weight Decay: 1.3502174401630838e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [943, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:45:27,134] Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6923\n",
      "  Elapsed time: 0:03:05.323158\n",
      "\n",
      "\n",
      "\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 84 finished with value: 0.6923 and parameters: {'learning_rate': 0.0003261243021880896, 'dropout_rate': 0.06525664504539422, 'weight_decay': 1.3502174401630838e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 85\n",
      "  Learning Rate: 0.00011944910587629197\n",
      "  Dropout Rate: 0.06528232943985117\n",
      "  Weight Decay: 1.0161493738644368e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [932, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:48:14,653] Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6505\n",
      "  Elapsed time: 0:02:47.414103\n",
      "\n",
      "\n",
      "\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 85 finished with value: 0.6505 and parameters: {'learning_rate': 0.00011944910587629197, 'dropout_rate': 0.06528232943985117, 'weight_decay': 1.0161493738644368e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 932.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 86\n",
      "  Learning Rate: 0.00023969147251862226\n",
      "  Dropout Rate: 0.1128067402270819\n",
      "  Weight Decay: 1.3382379029778512e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [953, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:51:15,184] Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6556\n",
      "  Elapsed time: 0:03:00.417937\n",
      "\n",
      "\n",
      "\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 86 finished with value: 0.6556 and parameters: {'learning_rate': 0.00023969147251862226, 'dropout_rate': 0.1128067402270819, 'weight_decay': 1.3382379029778512e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 87\n",
      "  Learning Rate: 0.00034879097692333034\n",
      "  Dropout Rate: 0.09354940863656214\n",
      "  Weight Decay: 1.8692969330135296e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [882, 411, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:53:04,392] Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6561\n",
      "  Elapsed time: 0:01:49.092983\n",
      "\n",
      "\n",
      "\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 87 finished with value: 0.6561 and parameters: {'learning_rate': 0.00034879097692333034, 'dropout_rate': 0.09354940863656214, 'weight_decay': 1.8692969330135296e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 882.0, 'layer-2-size': 411.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 88\n",
      "  Learning Rate: 0.00045043628572817926\n",
      "  Dropout Rate: 0.06288939470792108\n",
      "  Weight Decay: 3.641815221579397e-05\n",
      "  Number of Layers: 6\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [905, 275, 786, 379, 825, 10]\n",
      "\n",
      "  Accuracy: 0.6672\n",
      "  Elapsed time: 0:04:48.434064\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 09:57:53,184] Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 88 finished with value: 0.6672 and parameters: {'learning_rate': 0.00045043628572817926, 'dropout_rate': 0.06288939470792108, 'weight_decay': 3.641815221579397e-05, 'num_layers': 6.0, 'batch_size': 64, 'layer-1-size': 905.0, 'layer-2-size': 275.0, 'layer-3-size': 786.0, 'layer-4-size': 379.0, 'layer-5-size': 825.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 89\n",
      "  Learning Rate: 6.378832584009046e-05\n",
      "  Dropout Rate: 0.12562669128833143\n",
      "  Weight Decay: 0.00016430984011025959\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1004, 101, 10]\n",
      "\n",
      "  Accuracy: 0.5871\n",
      "  Elapsed time: 0:03:19.928728\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:01:13,482] Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 89 finished with value: 0.5871 and parameters: {'learning_rate': 6.378832584009046e-05, 'dropout_rate': 0.12562669128833143, 'weight_decay': 0.00016430984011025959, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1004.0, 'layer-2-size': 101.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 90\n",
      "  Learning Rate: 0.0009085417863219578\n",
      "  Dropout Rate: 0.08616049760566462\n",
      "  Weight Decay: 1.2153882849036647e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [822, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:04:17,854] Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6674\n",
      "  Elapsed time: 0:03:04.248408\n",
      "\n",
      "\n",
      "\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 90 finished with value: 0.6674 and parameters: {'learning_rate': 0.0009085417863219578, 'dropout_rate': 0.08616049760566462, 'weight_decay': 1.2153882849036647e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 822.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 91\n",
      "  Learning Rate: 0.000561056366702141\n",
      "  Dropout Rate: 0.15795664159224246\n",
      "  Weight Decay: 1.5339918531170402e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [966, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:07:08,987] Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6718\n",
      "  Elapsed time: 0:02:51.029934\n",
      "\n",
      "\n",
      "\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 91 finished with value: 0.6718 and parameters: {'learning_rate': 0.000561056366702141, 'dropout_rate': 0.15795664159224246, 'weight_decay': 1.5339918531170402e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 92\n",
      "  Learning Rate: 0.0002937644657637029\n",
      "  Dropout Rate: 0.10237855209275593\n",
      "  Weight Decay: 2.1574672571705246e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [986, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:10:06,028] Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6701\n",
      "  Elapsed time: 0:02:56.921590\n",
      "\n",
      "\n",
      "\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 92 finished with value: 0.6701 and parameters: {'learning_rate': 0.0002937644657637029, 'dropout_rate': 0.10237855209275593, 'weight_decay': 2.1574672571705246e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 93\n",
      "  Learning Rate: 0.0006869642121395982\n",
      "  Dropout Rate: 0.04822461216380804\n",
      "  Weight Decay: 0.005863615505614213\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [919, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:13:19,704] Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6397\n",
      "  Elapsed time: 0:03:13.561276\n",
      "\n",
      "\n",
      "\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 93 finished with value: 0.6397 and parameters: {'learning_rate': 0.0006869642121395982, 'dropout_rate': 0.04822461216380804, 'weight_decay': 0.005863615505614213, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 919.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 94\n",
      "  Learning Rate: 0.0004937519532203366\n",
      "  Dropout Rate: 0.07260060076835134\n",
      "  Weight Decay: 2.6212369773366087e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [856, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:16:16,586] Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6682\n",
      "  Elapsed time: 0:02:56.782996\n",
      "\n",
      "\n",
      "\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 94 finished with value: 0.6682 and parameters: {'learning_rate': 0.0004937519532203366, 'dropout_rate': 0.07260060076835134, 'weight_decay': 2.6212369773366087e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 856.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 95\n",
      "  Learning Rate: 0.0004096502731145876\n",
      "  Dropout Rate: 0.181060585589948\n",
      "  Weight Decay: 1.823735028283507e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [940, 356, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:20:18,018] Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6609\n",
      "  Elapsed time: 0:04:01.322316\n",
      "\n",
      "\n",
      "\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 95 finished with value: 0.6609 and parameters: {'learning_rate': 0.0004096502731145876, 'dropout_rate': 0.181060585589948, 'weight_decay': 1.823735028283507e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 940.0, 'layer-2-size': 356.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 96\n",
      "  Learning Rate: 0.00020589446456531843\n",
      "  Dropout Rate: 0.17024945451347362\n",
      "  Weight Decay: 1.3781627926330274e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1024, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:23:04,730] Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.648\n",
      "  Elapsed time: 0:02:46.587090\n",
      "\n",
      "\n",
      "\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 96 finished with value: 0.648 and parameters: {'learning_rate': 0.00020589446456531843, 'dropout_rate': 0.17024945451347362, 'weight_decay': 1.3781627926330274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 97\n",
      "  Learning Rate: 0.00032338407622490786\n",
      "  Dropout Rate: 0.13359156510140674\n",
      "  Weight Decay: 1.1419112645817321e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [976, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:26:13,941] Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6724\n",
      "  Elapsed time: 0:03:09.095531\n",
      "\n",
      "\n",
      "\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 97 finished with value: 0.6724 and parameters: {'learning_rate': 0.00032338407622490786, 'dropout_rate': 0.13359156510140674, 'weight_decay': 1.1419112645817321e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 976.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 98\n",
      "  Learning Rate: 0.0007798910804038147\n",
      "  Dropout Rate: 0.11189215463776779\n",
      "  Weight Decay: 1.4488524874520226e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1000, 741, 10]\n",
      "\n",
      "  Accuracy: 0.6743\n",
      "  Elapsed time: 0:05:10.767450\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:31:25,081] Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 98 finished with value: 0.6743 and parameters: {'learning_rate': 0.0007798910804038147, 'dropout_rate': 0.11189215463776779, 'weight_decay': 1.4488524874520226e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1000.0, 'layer-2-size': 741.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 99\n",
      "  Learning Rate: 2.4344338177669146e-05\n",
      "  Dropout Rate: 0.42842296518801704\n",
      "  Weight Decay: 1.001714023589318e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [958, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:33:15,930] Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.4685\n",
      "  Elapsed time: 0:01:50.742377\n",
      "\n",
      "\n",
      "\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 99 finished with value: 0.4685 and parameters: {'learning_rate': 2.4344338177669146e-05, 'dropout_rate': 0.42842296518801704, 'weight_decay': 1.001714023589318e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 958.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 100\n",
      "  Learning Rate: 0.0014190921830718375\n",
      "  Dropout Rate: 0.0777368734675708\n",
      "  Weight Decay: 2.3929534713277722e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [909, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:36:41,584] Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6659\n",
      "  Elapsed time: 0:03:25.544149\n",
      "\n",
      "\n",
      "\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 100 finished with value: 0.6659 and parameters: {'learning_rate': 0.0014190921830718375, 'dropout_rate': 0.0777368734675708, 'weight_decay': 2.3929534713277722e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 101\n",
      "  Learning Rate: 0.0006166401756464687\n",
      "  Dropout Rate: 0.06004568417014067\n",
      "  Weight Decay: 1.726808788532293e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1006, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:39:51,885] Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6731\n",
      "  Elapsed time: 0:03:10.195613\n",
      "\n",
      "\n",
      "\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 101 finished with value: 0.6731 and parameters: {'learning_rate': 0.0006166401756464687, 'dropout_rate': 0.06004568417014067, 'weight_decay': 1.726808788532293e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1006.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 102\n",
      "  Learning Rate: 0.0009679354960564465\n",
      "  Dropout Rate: 0.046967814003822606\n",
      "  Weight Decay: 3.0963748330545386e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [972, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:43:01,097] Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6726\n",
      "  Elapsed time: 0:03:09.106464\n",
      "\n",
      "\n",
      "\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 102 finished with value: 0.6726 and parameters: {'learning_rate': 0.0009679354960564465, 'dropout_rate': 0.046967814003822606, 'weight_decay': 3.0963748330545386e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 972.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 103\n",
      "  Learning Rate: 0.0011542297701588454\n",
      "  Dropout Rate: 0.09594753060034372\n",
      "  Weight Decay: 2.5699401403240557e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [942, 73, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:47:07,087] Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6916\n",
      "  Elapsed time: 0:04:05.880715\n",
      "\n",
      "\n",
      "\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 103 finished with value: 0.6916 and parameters: {'learning_rate': 0.0011542297701588454, 'dropout_rate': 0.09594753060034372, 'weight_decay': 2.5699401403240557e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 942.0, 'layer-2-size': 73.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 104\n",
      "  Learning Rate: 0.0005134496456210379\n",
      "  Dropout Rate: 0.08956291989492027\n",
      "  Weight Decay: 0.00040927041639079645\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [938, 77, 646, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:52:05,547] Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6697\n",
      "  Elapsed time: 0:04:58.364129\n",
      "\n",
      "\n",
      "\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 104 finished with value: 0.6697 and parameters: {'learning_rate': 0.0005134496456210379, 'dropout_rate': 0.08956291989492027, 'weight_decay': 0.00040927041639079645, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 938.0, 'layer-2-size': 77.0, 'layer-3-size': 646.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 105\n",
      "  Learning Rate: 0.0007509637514261306\n",
      "  Dropout Rate: 0.09891956110772143\n",
      "  Weight Decay: 1.30358748405311e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [889, 135, 10]\n",
      "\n",
      "  Accuracy: 0.6644\n",
      "  Elapsed time: 0:02:21.536639\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:54:27,431] Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 105 finished with value: 0.6644 and parameters: {'learning_rate': 0.0007509637514261306, 'dropout_rate': 0.09891956110772143, 'weight_decay': 1.30358748405311e-05, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 889.0, 'layer-2-size': 135.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 106\n",
      "  Learning Rate: 0.0002672953718403475\n",
      "  Dropout Rate: 0.15303148225039573\n",
      "  Weight Decay: 4.8967708706657935e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [924, 200, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 10:57:59,049] Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6698\n",
      "  Elapsed time: 0:03:31.509027\n",
      "\n",
      "\n",
      "\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 106 finished with value: 0.6698 and parameters: {'learning_rate': 0.0002672953718403475, 'dropout_rate': 0.15303148225039573, 'weight_decay': 4.8967708706657935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 924.0, 'layer-2-size': 200.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 107\n",
      "  Learning Rate: 0.0015672374144622728\n",
      "  Dropout Rate: 0.016998648027316265\n",
      "  Weight Decay: 1.8118077255892037e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [988, 177, 10]\n",
      "\n",
      "  Accuracy: 0.6439\n",
      "  Elapsed time: 0:04:49.023399\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:02:48,426] Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 107 finished with value: 0.6439 and parameters: {'learning_rate': 0.0015672374144622728, 'dropout_rate': 0.016998648027316265, 'weight_decay': 1.8118077255892037e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 177.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 108\n",
      "  Learning Rate: 0.0021343369099622203\n",
      "  Dropout Rate: 0.1201740352130869\n",
      "  Weight Decay: 2.621250251742537e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [956, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:06:34,813] Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6491\n",
      "  Elapsed time: 0:03:46.271196\n",
      "\n",
      "\n",
      "\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 108 finished with value: 0.6491 and parameters: {'learning_rate': 0.0021343369099622203, 'dropout_rate': 0.1201740352130869, 'weight_decay': 2.621250251742537e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 109\n",
      "  Learning Rate: 0.001055997248610119\n",
      "  Dropout Rate: 0.06948108126164568\n",
      "  Weight Decay: 2.2096526615126797e-05\n",
      "  Number of Layers: 9\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [700, 231, 128, 205, 509, 423, 123, 591, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:08:32,593] Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6102\n",
      "  Elapsed time: 0:01:57.667860\n",
      "\n",
      "\n",
      "\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 109 finished with value: 0.6102 and parameters: {'learning_rate': 0.001055997248610119, 'dropout_rate': 0.06948108126164568, 'weight_decay': 2.2096526615126797e-05, 'num_layers': 9.0, 'batch_size': 256, 'layer-1-size': 700.0, 'layer-2-size': 231.0, 'layer-3-size': 128.0, 'layer-4-size': 205.0, 'layer-5-size': 509.0, 'layer-6-size': 423.0, 'layer-7-size': 123.0, 'layer-8-size': 591.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 110\n",
      "  Learning Rate: 0.0012473020841651582\n",
      "  Dropout Rate: 0.2741555656623046\n",
      "  Weight Decay: 1.1063391618620562e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1007, 289, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:12:59,625] Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6386\n",
      "  Elapsed time: 0:04:26.924891\n",
      "\n",
      "\n",
      "\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 110 finished with value: 0.6386 and parameters: {'learning_rate': 0.0012473020841651582, 'dropout_rate': 0.2741555656623046, 'weight_decay': 1.1063391618620562e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1007.0, 'layer-2-size': 289.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 111\n",
      "  Learning Rate: 0.000628883752314661\n",
      "  Dropout Rate: 0.08354639381123116\n",
      "  Weight Decay: 1.5729200483294274e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1011, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:16:04,612] Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6699\n",
      "  Elapsed time: 0:03:04.880727\n",
      "\n",
      "\n",
      "\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 111 finished with value: 0.6699 and parameters: {'learning_rate': 0.000628883752314661, 'dropout_rate': 0.08354639381123116, 'weight_decay': 1.5729200483294274e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1011.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 112\n",
      "  Learning Rate: 0.0011711077274592138\n",
      "  Dropout Rate: 0.034256361018469274\n",
      "  Weight Decay: 1.9482707335268375e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [981, 10]\n",
      "\n",
      "  Accuracy: 0.6672\n",
      "  Elapsed time: 0:03:15.939433\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:19:20,913] Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 112 finished with value: 0.6672 and parameters: {'learning_rate': 0.0011711077274592138, 'dropout_rate': 0.034256361018469274, 'weight_decay': 1.9482707335268375e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 981.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 113\n",
      "  Learning Rate: 0.0008940029383648285\n",
      "  Dropout Rate: 0.1068521308879046\n",
      "  Weight Decay: 3.8534005585934114e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [943, 10]\n",
      "\n",
      "  Accuracy: 0.6807\n",
      "  Elapsed time: 0:03:12.662215\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:22:33,938] Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 113 finished with value: 0.6807 and parameters: {'learning_rate': 0.0008940029383648285, 'dropout_rate': 0.1068521308879046, 'weight_decay': 3.8534005585934114e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 114\n",
      "  Learning Rate: 0.00040786140369888696\n",
      "  Dropout Rate: 0.10561160608564668\n",
      "  Weight Decay: 1.2913589148744682e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [914, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:25:40,525] Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6659\n",
      "  Elapsed time: 0:03:06.483006\n",
      "\n",
      "\n",
      "\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 114 finished with value: 0.6659 and parameters: {'learning_rate': 0.00040786140369888696, 'dropout_rate': 0.10561160608564668, 'weight_decay': 1.2913589148744682e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 115\n",
      "  Learning Rate: 0.0008702272229412605\n",
      "  Dropout Rate: 0.11646191520593074\n",
      "  Weight Decay: 4.0307042891987575e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [867, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:28:46,429] Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6709\n",
      "  Elapsed time: 0:03:05.792379\n",
      "\n",
      "\n",
      "\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 115 finished with value: 0.6709 and parameters: {'learning_rate': 0.0008702272229412605, 'dropout_rate': 0.11646191520593074, 'weight_decay': 4.0307042891987575e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 867.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 116\n",
      "  Learning Rate: 0.0007149965094391944\n",
      "  Dropout Rate: 0.19321006666776416\n",
      "  Weight Decay: 1.5580312422456568e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [937, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:31:46,876] Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6822\n",
      "  Elapsed time: 0:03:00.342426\n",
      "\n",
      "\n",
      "\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 116 finished with value: 0.6822 and parameters: {'learning_rate': 0.0007149965094391944, 'dropout_rate': 0.19321006666776416, 'weight_decay': 1.5580312422456568e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 117\n",
      "  Learning Rate: 0.0007391790900430754\n",
      "  Dropout Rate: 0.12954178774730135\n",
      "  Weight Decay: 1.431687926025833e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [941, 153, 10]\n",
      "\n",
      "  Accuracy: 0.6846\n",
      "  Elapsed time: 0:03:53.158809\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:35:40,390] Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 117 finished with value: 0.6846 and parameters: {'learning_rate': 0.0007391790900430754, 'dropout_rate': 0.12954178774730135, 'weight_decay': 1.431687926025833e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 941.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 118\n",
      "  Learning Rate: 0.001704953669875381\n",
      "  Dropout Rate: 0.09557086457038053\n",
      "  Weight Decay: 1.1942439525144538e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [899, 137, 709, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:37:11,805] Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6387\n",
      "  Elapsed time: 0:01:31.306134\n",
      "\n",
      "\n",
      "\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 118 finished with value: 0.6387 and parameters: {'learning_rate': 0.001704953669875381, 'dropout_rate': 0.09557086457038053, 'weight_decay': 1.1942439525144538e-05, 'num_layers': 4.0, 'batch_size': 256, 'layer-1-size': 899.0, 'layer-2-size': 137.0, 'layer-3-size': 709.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 119\n",
      "  Learning Rate: 0.0007249535385585759\n",
      "  Dropout Rate: 0.13496384598383504\n",
      "  Weight Decay: 1.4519157739132655e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [933, 186, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:41:16,911] Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6722\n",
      "  Elapsed time: 0:04:04.985423\n",
      "\n",
      "\n",
      "\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 119 finished with value: 0.6722 and parameters: {'learning_rate': 0.0007249535385585759, 'dropout_rate': 0.13496384598383504, 'weight_decay': 1.4519157739132655e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 186.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 120\n",
      "  Learning Rate: 0.0009688664939441259\n",
      "  Dropout Rate: 0.05230394777216092\n",
      "  Weight Decay: 2.106288980070317e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [961, 120, 526, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:46:18,304] Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6625\n",
      "  Elapsed time: 0:05:01.290940\n",
      "\n",
      "\n",
      "\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 120 finished with value: 0.6625 and parameters: {'learning_rate': 0.0009688664939441259, 'dropout_rate': 0.05230394777216092, 'weight_decay': 2.106288980070317e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 961.0, 'layer-2-size': 120.0, 'layer-3-size': 526.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 121\n",
      "  Learning Rate: 0.0006139151486554264\n",
      "  Dropout Rate: 0.16294079628048425\n",
      "  Weight Decay: 1.657186155863935e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [946, 66, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:49:40,835] Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6783\n",
      "  Elapsed time: 0:03:22.419131\n",
      "\n",
      "\n",
      "\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 121 finished with value: 0.6783 and parameters: {'learning_rate': 0.0006139151486554264, 'dropout_rate': 0.16294079628048425, 'weight_decay': 1.657186155863935e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 946.0, 'layer-2-size': 66.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 122\n",
      "  Learning Rate: 0.0006117494578517395\n",
      "  Dropout Rate: 0.16540912202856164\n",
      "  Weight Decay: 1.1336660480169866e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [289, 70, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:52:34,385] Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6464\n",
      "  Elapsed time: 0:02:53.444852\n",
      "\n",
      "\n",
      "\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 122 finished with value: 0.6464 and parameters: {'learning_rate': 0.0006117494578517395, 'dropout_rate': 0.16540912202856164, 'weight_decay': 1.1336660480169866e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 289.0, 'layer-2-size': 70.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 123\n",
      "  Learning Rate: 0.000834204412139856\n",
      "  Dropout Rate: 0.19922861037793593\n",
      "  Weight Decay: 1.3710395897860321e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [888, 158, 10]\n",
      "\n",
      "  Accuracy: 0.6751\n",
      "  Elapsed time: 0:03:43.891528\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 11:56:18,612] Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 123 finished with value: 0.6751 and parameters: {'learning_rate': 0.000834204412139856, 'dropout_rate': 0.19922861037793593, 'weight_decay': 1.3710395897860321e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 888.0, 'layer-2-size': 158.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 124\n",
      "  Learning Rate: 0.0013666419282976402\n",
      "  Dropout Rate: 0.07664847194097621\n",
      "  Weight Decay: 2.4198558239742658e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [943, 67, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:00:29,856] Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.662\n",
      "  Elapsed time: 0:04:11.144661\n",
      "\n",
      "\n",
      "\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 124 finished with value: 0.662 and parameters: {'learning_rate': 0.0013666419282976402, 'dropout_rate': 0.07664847194097621, 'weight_decay': 2.4198558239742658e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 943.0, 'layer-2-size': 67.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 125\n",
      "  Learning Rate: 0.0006799010535799528\n",
      "  Dropout Rate: 0.12483092746463025\n",
      "  Weight Decay: 1.001849423411822e-05\n",
      "  Number of Layers: 7\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [913, 1018, 830, 1019, 216, 794, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:14:16,648] Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6482\n",
      "  Elapsed time: 0:13:46.676182\n",
      "\n",
      "\n",
      "\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 125 finished with value: 0.6482 and parameters: {'learning_rate': 0.0006799010535799528, 'dropout_rate': 0.12483092746463025, 'weight_decay': 1.001849423411822e-05, 'num_layers': 7.0, 'batch_size': 32, 'layer-1-size': 913.0, 'layer-2-size': 1018.0, 'layer-3-size': 830.0, 'layer-4-size': 1019.0, 'layer-5-size': 216.0, 'layer-6-size': 794.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 126\n",
      "  Learning Rate: 0.001031541540940216\n",
      "  Dropout Rate: 0.10477504138182234\n",
      "  Weight Decay: 1.7318924769609437e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [963, 226, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:16:17,594] Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6676\n",
      "  Elapsed time: 0:02:00.840027\n",
      "\n",
      "\n",
      "\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 126 finished with value: 0.6676 and parameters: {'learning_rate': 0.001031541540940216, 'dropout_rate': 0.10477504138182234, 'weight_decay': 1.7318924769609437e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 963.0, 'layer-2-size': 226.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 127\n",
      "  Learning Rate: 0.0005708387379893043\n",
      "  Dropout Rate: 0.32998857725649794\n",
      "  Weight Decay: 2.0388879915545942e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [994, 97, 570, 10]\n",
      "\n",
      "  Accuracy: 0.6236\n",
      "  Elapsed time: 0:04:15.306004\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:20:33,256] Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 127 finished with value: 0.6236 and parameters: {'learning_rate': 0.0005708387379893043, 'dropout_rate': 0.32998857725649794, 'weight_decay': 2.0388879915545942e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 994.0, 'layer-2-size': 97.0, 'layer-3-size': 570.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 128\n",
      "  Learning Rate: 0.00036458557847955083\n",
      "  Dropout Rate: 0.06652293685289927\n",
      "  Weight Decay: 0.00095304155492976\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [927, 255, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:23:29,997] Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6597\n",
      "  Elapsed time: 0:02:56.634137\n",
      "\n",
      "\n",
      "\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 128 finished with value: 0.6597 and parameters: {'learning_rate': 0.00036458557847955083, 'dropout_rate': 0.06652293685289927, 'weight_decay': 0.00095304155492976, 'num_layers': 3.0, 'batch_size': 64, 'layer-1-size': 927.0, 'layer-2-size': 255.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 129\n",
      "  Learning Rate: 0.0004824891563003007\n",
      "  Dropout Rate: 0.1365285792605903\n",
      "  Weight Decay: 1.4959049870155674e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [665, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:26:32,252] Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6712\n",
      "  Elapsed time: 0:03:02.140271\n",
      "\n",
      "\n",
      "\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 129 finished with value: 0.6712 and parameters: {'learning_rate': 0.0004824891563003007, 'dropout_rate': 0.1365285792605903, 'weight_decay': 1.4959049870155674e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 665.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 130\n",
      "  Learning Rate: 0.0009249003400562095\n",
      "  Dropout Rate: 0.22226008953907417\n",
      "  Weight Decay: 6.926879586010967e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [860, 10]\n",
      "\n",
      "  Accuracy: 0.6525\n",
      "  Elapsed time: 0:05:42.334490\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:32:14,941] Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 130 finished with value: 0.6525 and parameters: {'learning_rate': 0.0009249003400562095, 'dropout_rate': 0.22226008953907417, 'weight_decay': 6.926879586010967e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 860.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 131\n",
      "  Learning Rate: 0.00046306771109771896\n",
      "  Dropout Rate: 0.14578803410015095\n",
      "  Weight Decay: 1.6160050725198243e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [955, 10]\n",
      "\n",
      "  Accuracy: 0.6661\n",
      "  Elapsed time: 0:03:02.982100\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:35:18,273] Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 131 finished with value: 0.6661 and parameters: {'learning_rate': 0.00046306771109771896, 'dropout_rate': 0.14578803410015095, 'weight_decay': 1.6160050725198243e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 132\n",
      "  Learning Rate: 0.0007736489996983828\n",
      "  Dropout Rate: 0.19301285703969817\n",
      "  Weight Decay: 1.24688165652938e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [940, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:38:18,795] Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.663\n",
      "  Elapsed time: 0:03:00.420080\n",
      "\n",
      "\n",
      "\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 132 finished with value: 0.663 and parameters: {'learning_rate': 0.0007736489996983828, 'dropout_rate': 0.19301285703969817, 'weight_decay': 1.24688165652938e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 133\n",
      "  Learning Rate: 0.00032240724619646597\n",
      "  Dropout Rate: 0.08811953170399946\n",
      "  Weight Decay: 2.8418558759275534e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [974, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:41:25,949] Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6812\n",
      "  Elapsed time: 0:03:07.043843\n",
      "\n",
      "\n",
      "\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 133 finished with value: 0.6812 and parameters: {'learning_rate': 0.00032240724619646597, 'dropout_rate': 0.08811953170399946, 'weight_decay': 2.8418558759275534e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 974.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 134\n",
      "  Learning Rate: 0.00016316526720006473\n",
      "  Dropout Rate: 0.08080492110913869\n",
      "  Weight Decay: 2.8287676474192457e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [980, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:44:28,428] Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6632\n",
      "  Elapsed time: 0:03:02.376156\n",
      "\n",
      "\n",
      "\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 134 finished with value: 0.6632 and parameters: {'learning_rate': 0.00016316526720006473, 'dropout_rate': 0.08080492110913869, 'weight_decay': 2.8287676474192457e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 980.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 135\n",
      "  Learning Rate: 0.0011404143230075183\n",
      "  Dropout Rate: 0.08902580373904093\n",
      "  Weight Decay: 3.277143750599645e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1011, 308, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:49:43,674] Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6607\n",
      "  Elapsed time: 0:05:15.140055\n",
      "\n",
      "\n",
      "\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 135 finished with value: 0.6607 and parameters: {'learning_rate': 0.0011404143230075183, 'dropout_rate': 0.08902580373904093, 'weight_decay': 3.277143750599645e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1011.0, 'layer-2-size': 308.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 136\n",
      "  Learning Rate: 0.0003217897064928789\n",
      "  Dropout Rate: 0.09531234235754027\n",
      "  Weight Decay: 2.537931173660316e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [988, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:51:20,870] Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6348\n",
      "  Elapsed time: 0:01:37.088274\n",
      "\n",
      "\n",
      "\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 136 finished with value: 0.6348 and parameters: {'learning_rate': 0.0003217897064928789, 'dropout_rate': 0.09531234235754027, 'weight_decay': 2.537931173660316e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 988.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 137\n",
      "  Learning Rate: 0.0005857581954522988\n",
      "  Dropout Rate: 0.10801736778930576\n",
      "  Weight Decay: 1.9318921347624347e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1023, 153, 10]\n",
      "\n",
      "  Accuracy: 0.6766\n",
      "  Elapsed time: 0:03:47.296949\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:55:08,535] Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 137 finished with value: 0.6766 and parameters: {'learning_rate': 0.0005857581954522988, 'dropout_rate': 0.10801736778930576, 'weight_decay': 1.9318921347624347e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1023.0, 'layer-2-size': 153.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 138\n",
      "  Learning Rate: 0.00022426128448295107\n",
      "  Dropout Rate: 0.05651215366597729\n",
      "  Weight Decay: 1.3662057944113446e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [788, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 12:58:03,202] Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6626\n",
      "  Elapsed time: 0:02:54.546981\n",
      "\n",
      "\n",
      "\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 138 finished with value: 0.6626 and parameters: {'learning_rate': 0.00022426128448295107, 'dropout_rate': 0.05651215366597729, 'weight_decay': 1.3662057944113446e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 788.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 139\n",
      "  Learning Rate: 0.0028314309972643403\n",
      "  Dropout Rate: 0.2516121767964616\n",
      "  Weight Decay: 2.2220289738080744e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [917, 10]\n",
      "\n",
      "  Accuracy: 0.6487\n",
      "  Elapsed time: 0:04:05.252237\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:02:08,811] Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 139 finished with value: 0.6487 and parameters: {'learning_rate': 0.0028314309972643403, 'dropout_rate': 0.2516121767964616, 'weight_decay': 2.2220289738080744e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 917.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 140\n",
      "  Learning Rate: 0.00037992496033435356\n",
      "  Dropout Rate: 0.12647588558995193\n",
      "  Weight Decay: 3.755607617695702e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [501, 203, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:05:25,180] Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6734\n",
      "  Elapsed time: 0:03:16.252828\n",
      "\n",
      "\n",
      "\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 140 finished with value: 0.6734 and parameters: {'learning_rate': 0.00037992496033435356, 'dropout_rate': 0.12647588558995193, 'weight_decay': 3.755607617695702e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 501.0, 'layer-2-size': 203.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 141\n",
      "  Learning Rate: 0.0004593949857690816\n",
      "  Dropout Rate: 0.14655010755759146\n",
      "  Weight Decay: 1.7274158700369202e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [966, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:08:27,233] Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6766\n",
      "  Elapsed time: 0:03:01.941737\n",
      "\n",
      "\n",
      "\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 141 finished with value: 0.6766 and parameters: {'learning_rate': 0.0004593949857690816, 'dropout_rate': 0.14655010755759146, 'weight_decay': 1.7274158700369202e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 966.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 142\n",
      "  Learning Rate: 0.0006846616717109179\n",
      "  Dropout Rate: 0.16373623736786058\n",
      "  Weight Decay: 1.1385601256192846e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [943, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:11:35,835] Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6737\n",
      "  Elapsed time: 0:03:08.443534\n",
      "\n",
      "\n",
      "\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 142 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006846616717109179, 'dropout_rate': 0.16373623736786058, 'weight_decay': 1.1385601256192846e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 143\n",
      "  Learning Rate: 0.00028631115401955766\n",
      "  Dropout Rate: 0.06995285400260416\n",
      "  Weight Decay: 1.5763348101278117e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [965, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:14:35,508] Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6736\n",
      "  Elapsed time: 0:02:59.557101\n",
      "\n",
      "\n",
      "\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 143 finished with value: 0.6736 and parameters: {'learning_rate': 0.00028631115401955766, 'dropout_rate': 0.06995285400260416, 'weight_decay': 1.5763348101278117e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 144\n",
      "  Learning Rate: 0.00041803175284644536\n",
      "  Dropout Rate: 0.15329446601818128\n",
      "  Weight Decay: 1.3635137220332118e-05\n",
      "  Number of Layers: 8\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [889, 119, 947, 853, 660, 96, 669, 10]\n",
      "\n",
      "  Accuracy: 0.6344\n",
      "  Elapsed time: 0:11:10.488478\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:25:46,359] Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 144 finished with value: 0.6344 and parameters: {'learning_rate': 0.00041803175284644536, 'dropout_rate': 0.15329446601818128, 'weight_decay': 1.3635137220332118e-05, 'num_layers': 8.0, 'batch_size': 32, 'layer-1-size': 889.0, 'layer-2-size': 119.0, 'layer-3-size': 947.0, 'layer-4-size': 853.0, 'layer-5-size': 660.0, 'layer-6-size': 96.0, 'layer-7-size': 669.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 145\n",
      "  Learning Rate: 0.0005350334240329538\n",
      "  Dropout Rate: 0.11404587947762619\n",
      "  Weight Decay: 1.8682899031679118e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [948, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:28:50,133] Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.682\n",
      "  Elapsed time: 0:03:03.627813\n",
      "\n",
      "\n",
      "\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 145 finished with value: 0.682 and parameters: {'learning_rate': 0.0005350334240329538, 'dropout_rate': 0.11404587947762619, 'weight_decay': 1.8682899031679118e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 146\n",
      "  Learning Rate: 0.0007890522719047026\n",
      "  Dropout Rate: 0.11604200950554816\n",
      "  Weight Decay: 1.9248523943645827e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [989, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:32:00,134] Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6898\n",
      "  Elapsed time: 0:03:09.892739\n",
      "\n",
      "\n",
      "\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 146 finished with value: 0.6898 and parameters: {'learning_rate': 0.0007890522719047026, 'dropout_rate': 0.11604200950554816, 'weight_decay': 1.9248523943645827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 147\n",
      "  Learning Rate: 0.0005333797497796335\n",
      "  Dropout Rate: 0.12397773935508156\n",
      "  Weight Decay: 2.9173462101906107e-05\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [926, 88, 80, 597, 10]\n",
      "\n",
      "  Accuracy: 0.6553\n",
      "  Elapsed time: 0:04:33.940033\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:36:34,438] Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 147 finished with value: 0.6553 and parameters: {'learning_rate': 0.0005333797497796335, 'dropout_rate': 0.12397773935508156, 'weight_decay': 2.9173462101906107e-05, 'num_layers': 5.0, 'batch_size': 32, 'layer-1-size': 926.0, 'layer-2-size': 88.0, 'layer-3-size': 80.0, 'layer-4-size': 597.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 148\n",
      "  Learning Rate: 0.0007602871063749105\n",
      "  Dropout Rate: 0.10157440835417918\n",
      "  Weight Decay: 1.9715822754510646e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [726, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:38:04,977] Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6522\n",
      "  Elapsed time: 0:01:30.437562\n",
      "\n",
      "\n",
      "\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 148 finished with value: 0.6522 and parameters: {'learning_rate': 0.0007602871063749105, 'dropout_rate': 0.10157440835417918, 'weight_decay': 1.9715822754510646e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 726.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 149\n",
      "  Learning Rate: 0.0006576445477844653\n",
      "  Dropout Rate: 0.11438514189570813\n",
      "  Weight Decay: 2.301799269374784e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [602, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:41:13,806] Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6759\n",
      "  Elapsed time: 0:03:08.715255\n",
      "\n",
      "\n",
      "\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 149 finished with value: 0.6759 and parameters: {'learning_rate': 0.0006576445477844653, 'dropout_rate': 0.11438514189570813, 'weight_decay': 2.301799269374784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 602.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 150\n",
      "  Learning Rate: 0.0003484620344681149\n",
      "  Dropout Rate: 0.0879677235598395\n",
      "  Weight Decay: 1.1836849084627518e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [975, 178, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:44:35,654] Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6788\n",
      "  Elapsed time: 0:03:21.736835\n",
      "\n",
      "\n",
      "\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 150 finished with value: 0.6788 and parameters: {'learning_rate': 0.0003484620344681149, 'dropout_rate': 0.0879677235598395, 'weight_decay': 1.1836849084627518e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 178.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 151\n",
      "  Learning Rate: 0.00032620419595438404\n",
      "  Dropout Rate: 0.09429593471650251\n",
      "  Weight Decay: 1.1717977900403427e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [974, 185, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:48:11,012] Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6663\n",
      "  Elapsed time: 0:03:35.257040\n",
      "\n",
      "\n",
      "\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 151 finished with value: 0.6663 and parameters: {'learning_rate': 0.00032620419595438404, 'dropout_rate': 0.09429593471650251, 'weight_decay': 1.1717977900403427e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 974.0, 'layer-2-size': 185.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 152\n",
      "  Learning Rate: 0.0005328963416617421\n",
      "  Dropout Rate: 0.08187423328941956\n",
      "  Weight Decay: 1.4933123521897081e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [950, 142, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:51:40,166] Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6565\n",
      "  Elapsed time: 0:03:29.043003\n",
      "\n",
      "\n",
      "\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 152 finished with value: 0.6565 and parameters: {'learning_rate': 0.0005328963416617421, 'dropout_rate': 0.08187423328941956, 'weight_decay': 1.4933123521897081e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 950.0, 'layer-2-size': 142.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 153\n",
      "  Learning Rate: 0.0003840735827858071\n",
      "  Dropout Rate: 0.11523905049147659\n",
      "  Weight Decay: 1.0792731910021608e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [907, 265, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:55:07,194] Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6738\n",
      "  Elapsed time: 0:03:26.930724\n",
      "\n",
      "\n",
      "\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 153 finished with value: 0.6738 and parameters: {'learning_rate': 0.0003840735827858071, 'dropout_rate': 0.11523905049147659, 'weight_decay': 1.0792731910021608e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 907.0, 'layer-2-size': 265.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 154\n",
      "  Learning Rate: 0.00026064854770996206\n",
      "  Dropout Rate: 0.08793993763226596\n",
      "  Weight Decay: 1.2682428629838535e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [995, 120, 607, 10]\n",
      "\n",
      "  Accuracy: 0.666\n",
      "  Elapsed time: 0:03:47.615584\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 13:58:55,184] Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 154 finished with value: 0.666 and parameters: {'learning_rate': 0.00026064854770996206, 'dropout_rate': 0.08793993763226596, 'weight_decay': 1.2682428629838535e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 120.0, 'layer-3-size': 607.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 155\n",
      "  Learning Rate: 0.0008201164932433455\n",
      "  Dropout Rate: 0.11051740813505923\n",
      "  Weight Decay: 1.869081964126608e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [973, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:02:06,969] Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6782\n",
      "  Elapsed time: 0:03:11.636927\n",
      "\n",
      "\n",
      "\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 155 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008201164932433455, 'dropout_rate': 0.11051740813505923, 'weight_decay': 1.869081964126608e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 156\n",
      "  Learning Rate: 0.0006241579674333816\n",
      "  Dropout Rate: 0.1307549283989793\n",
      "  Weight Decay: 1.4360413324702282e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [933, 167, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:05:55,806] Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6566\n",
      "  Elapsed time: 0:03:48.735608\n",
      "\n",
      "\n",
      "\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 156 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006241579674333816, 'dropout_rate': 0.1307549283989793, 'weight_decay': 1.4360413324702282e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 933.0, 'layer-2-size': 167.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 157\n",
      "  Learning Rate: 0.0002150119249645594\n",
      "  Dropout Rate: 0.07561445145810708\n",
      "  Weight Decay: 1.2370292239975514e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [993, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:08:56,337] Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6726\n",
      "  Elapsed time: 0:03:00.418319\n",
      "\n",
      "\n",
      "\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 157 finished with value: 0.6726 and parameters: {'learning_rate': 0.0002150119249645594, 'dropout_rate': 0.07561445145810708, 'weight_decay': 1.2370292239975514e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 993.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 158\n",
      "  Learning Rate: 0.001957311866065078\n",
      "  Dropout Rate: 0.0992834899015209\n",
      "  Weight Decay: 1.0005425513159997e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [953, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:11:11,035] Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6773\n",
      "  Elapsed time: 0:02:14.582292\n",
      "\n",
      "\n",
      "\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 158 finished with value: 0.6773 and parameters: {'learning_rate': 0.001957311866065078, 'dropout_rate': 0.0992834899015209, 'weight_decay': 1.0005425513159997e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 159\n",
      "  Learning Rate: 0.00033030852785788893\n",
      "  Dropout Rate: 0.13782918062395394\n",
      "  Weight Decay: 9.35490175997992e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [975, 331, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:15:22,089] Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6886\n",
      "  Elapsed time: 0:04:10.954719\n",
      "\n",
      "\n",
      "\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 159 finished with value: 0.6886 and parameters: {'learning_rate': 0.00033030852785788893, 'dropout_rate': 0.13782918062395394, 'weight_decay': 9.35490175997992e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 975.0, 'layer-2-size': 331.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 160\n",
      "  Learning Rate: 0.00033934928602694786\n",
      "  Dropout Rate: 0.08872169826461083\n",
      "  Weight Decay: 9.602883124368853e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [424, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:18:18,738] Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6657\n",
      "  Elapsed time: 0:02:56.538186\n",
      "\n",
      "\n",
      "\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 160 finished with value: 0.6657 and parameters: {'learning_rate': 0.00033934928602694786, 'dropout_rate': 0.08872169826461083, 'weight_decay': 9.602883124368853e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 424.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 161\n",
      "  Learning Rate: 0.00030074875923292175\n",
      "  Dropout Rate: 0.13649889492213085\n",
      "  Weight Decay: 0.00020608268260623438\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [970, 236, 10]\n",
      "\n",
      "  Accuracy: 0.6546\n",
      "  Elapsed time: 0:04:09.023959\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:22:28,103] Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 161 finished with value: 0.6546 and parameters: {'learning_rate': 0.00030074875923292175, 'dropout_rate': 0.13649889492213085, 'weight_decay': 0.00020608268260623438, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 970.0, 'layer-2-size': 236.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 162\n",
      "  Learning Rate: 0.0002544692386429786\n",
      "  Dropout Rate: 0.12035067688890208\n",
      "  Weight Decay: 5.08790204378485e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [995, 334, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:26:14,825] Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.679\n",
      "  Elapsed time: 0:03:46.605466\n",
      "\n",
      "\n",
      "\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 162 finished with value: 0.679 and parameters: {'learning_rate': 0.0002544692386429786, 'dropout_rate': 0.12035067688890208, 'weight_decay': 5.08790204378485e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 995.0, 'layer-2-size': 334.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 163\n",
      "  Learning Rate: 0.00028630995935578784\n",
      "  Dropout Rate: 0.11881046679145932\n",
      "  Weight Decay: 4.3756537615700614e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [1009, 448, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:28:16,621] Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6563\n",
      "  Elapsed time: 0:02:01.699434\n",
      "\n",
      "\n",
      "\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 163 finished with value: 0.6563 and parameters: {'learning_rate': 0.00028630995935578784, 'dropout_rate': 0.11881046679145932, 'weight_decay': 4.3756537615700614e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1009.0, 'layer-2-size': 448.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 164\n",
      "  Learning Rate: 0.00017451843683378334\n",
      "  Dropout Rate: 0.10308932012029567\n",
      "  Weight Decay: 5.0848071784326244e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [988, 342, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:31:49,239] Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6446\n",
      "  Elapsed time: 0:03:32.513873\n",
      "\n",
      "\n",
      "\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 164 finished with value: 0.6446 and parameters: {'learning_rate': 0.00017451843683378334, 'dropout_rate': 0.10308932012029567, 'weight_decay': 5.0848071784326244e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 988.0, 'layer-2-size': 342.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 165\n",
      "  Learning Rate: 0.0002372232822352455\n",
      "  Dropout Rate: 0.1263920634373015\n",
      "  Weight Decay: 6.648532066295951e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [997, 10]\n",
      "\n",
      "  Accuracy: 0.6602\n",
      "  Elapsed time: 0:05:01.380850\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:36:50,964] Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 165 finished with value: 0.6602 and parameters: {'learning_rate': 0.0002372232822352455, 'dropout_rate': 0.1263920634373015, 'weight_decay': 6.648532066295951e-05, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 997.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 166\n",
      "  Learning Rate: 0.00025555786030376725\n",
      "  Dropout Rate: 0.1079481872474693\n",
      "  Weight Decay: 5.730951373894122e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1016, 517, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:41:00,685] Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6686\n",
      "  Elapsed time: 0:04:09.601249\n",
      "\n",
      "\n",
      "\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 166 finished with value: 0.6686 and parameters: {'learning_rate': 0.00025555786030376725, 'dropout_rate': 0.1079481872474693, 'weight_decay': 5.730951373894122e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 1016.0, 'layer-2-size': 517.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 167\n",
      "  Learning Rate: 0.00042326218760383523\n",
      "  Dropout Rate: 0.06925306605496026\n",
      "  Weight Decay: 0.00011743119896247113\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1024, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:44:15,886] Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6676\n",
      "  Elapsed time: 0:03:15.093805\n",
      "\n",
      "\n",
      "\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 167 finished with value: 0.6676 and parameters: {'learning_rate': 0.00042326218760383523, 'dropout_rate': 0.06925306605496026, 'weight_decay': 0.00011743119896247113, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1024.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 168\n",
      "  Learning Rate: 0.0003581830534453256\n",
      "  Dropout Rate: 0.08142624875392467\n",
      "  Weight Decay: 3.371639777225744e-05\n",
      "  Number of Layers: 4\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [980, 398, 332, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:49:18,678] Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6648\n",
      "  Elapsed time: 0:05:02.695382\n",
      "\n",
      "\n",
      "\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 168 finished with value: 0.6648 and parameters: {'learning_rate': 0.0003581830534453256, 'dropout_rate': 0.08142624875392467, 'weight_decay': 3.371639777225744e-05, 'num_layers': 4.0, 'batch_size': 32, 'layer-1-size': 980.0, 'layer-2-size': 398.0, 'layer-3-size': 332.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 169\n",
      "  Learning Rate: 0.00020236661037460532\n",
      "  Dropout Rate: 0.09269878029918902\n",
      "  Weight Decay: 3.815313241357396e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [928, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:50:53,425] Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6144\n",
      "  Elapsed time: 0:01:34.635264\n",
      "\n",
      "\n",
      "\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 169 finished with value: 0.6144 and parameters: {'learning_rate': 0.00020236661037460532, 'dropout_rate': 0.09269878029918902, 'weight_decay': 3.815313241357396e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 928.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 170\n",
      "  Learning Rate: 0.00047900123040414493\n",
      "  Dropout Rate: 0.1150021577431907\n",
      "  Weight Decay: 2.6489898949769804e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [960, 299, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:55:03,112] Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6768\n",
      "  Elapsed time: 0:04:09.577674\n",
      "\n",
      "\n",
      "\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 170 finished with value: 0.6768 and parameters: {'learning_rate': 0.00047900123040414493, 'dropout_rate': 0.1150021577431907, 'weight_decay': 2.6489898949769804e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 960.0, 'layer-2-size': 299.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 171\n",
      "  Learning Rate: 0.0007134734108117302\n",
      "  Dropout Rate: 0.18244840462249087\n",
      "  Weight Decay: 1.6018808534892092e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [945, 210, 10]\n",
      "\n",
      "  Accuracy: 0.6683\n",
      "  Elapsed time: 0:04:01.880741\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 14:59:05,349] Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 171 finished with value: 0.6683 and parameters: {'learning_rate': 0.0007134734108117302, 'dropout_rate': 0.18244840462249087, 'weight_decay': 1.6018808534892092e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 945.0, 'layer-2-size': 210.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 172\n",
      "  Learning Rate: 0.0005793954435571951\n",
      "  Dropout Rate: 0.16217658796592171\n",
      "  Weight Decay: 2.1330276766501302e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [948, 326, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:03:28,766] Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6829\n",
      "  Elapsed time: 0:04:23.312393\n",
      "\n",
      "\n",
      "\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 172 finished with value: 0.6829 and parameters: {'learning_rate': 0.0005793954435571951, 'dropout_rate': 0.16217658796592171, 'weight_decay': 2.1330276766501302e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 948.0, 'layer-2-size': 326.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 173\n",
      "  Learning Rate: 0.0010542912159098204\n",
      "  Dropout Rate: 0.13783841374645614\n",
      "  Weight Decay: 7.716107921122614e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [553, 374, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:08:01,228] Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6685\n",
      "  Elapsed time: 0:04:32.350707\n",
      "\n",
      "\n",
      "\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 173 finished with value: 0.6685 and parameters: {'learning_rate': 0.0010542912159098204, 'dropout_rate': 0.13783841374645614, 'weight_decay': 7.716107921122614e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 553.0, 'layer-2-size': 374.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 174\n",
      "  Learning Rate: 0.0005610670540585006\n",
      "  Dropout Rate: 0.39013098939359014\n",
      "  Weight Decay: 2.1669572535311396e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [977, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:11:14,879] Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6294\n",
      "  Elapsed time: 0:03:13.541997\n",
      "\n",
      "\n",
      "\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 174 finished with value: 0.6294 and parameters: {'learning_rate': 0.0005610670540585006, 'dropout_rate': 0.39013098939359014, 'weight_decay': 2.1669572535311396e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 977.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 175\n",
      "  Learning Rate: 0.000816156585184187\n",
      "  Dropout Rate: 0.17241952435214877\n",
      "  Weight Decay: 3.2817970032597285e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [902, 325, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:16:22,136] Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6772\n",
      "  Elapsed time: 0:05:07.157855\n",
      "\n",
      "\n",
      "\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 175 finished with value: 0.6772 and parameters: {'learning_rate': 0.000816156585184187, 'dropout_rate': 0.17241952435214877, 'weight_decay': 3.2817970032597285e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 902.0, 'layer-2-size': 325.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 176\n",
      "  Learning Rate: 0.0005093159558665584\n",
      "  Dropout Rate: 0.1525170386315447\n",
      "  Weight Decay: 2.516490179897598e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [959, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:19:26,953] Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6819\n",
      "  Elapsed time: 0:03:04.672740\n",
      "\n",
      "\n",
      "\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 176 finished with value: 0.6819 and parameters: {'learning_rate': 0.0005093159558665584, 'dropout_rate': 0.1525170386315447, 'weight_decay': 2.516490179897598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 959.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 177\n",
      "  Learning Rate: 0.0009091931716220334\n",
      "  Dropout Rate: 0.15562940828586438\n",
      "  Weight Decay: 2.7877729665394984e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [925, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:22:42,402] Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6748\n",
      "  Elapsed time: 0:03:15.333718\n",
      "\n",
      "\n",
      "\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 177 finished with value: 0.6748 and parameters: {'learning_rate': 0.0009091931716220334, 'dropout_rate': 0.15562940828586438, 'weight_decay': 2.7877729665394984e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 925.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 178\n",
      "  Learning Rate: 0.0005389868250358188\n",
      "  Dropout Rate: 0.1366437223236197\n",
      "  Weight Decay: 1.986548821067462e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [955, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:25:48,081] Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6793\n",
      "  Elapsed time: 0:03:05.575480\n",
      "\n",
      "\n",
      "\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 178 finished with value: 0.6793 and parameters: {'learning_rate': 0.0005389868250358188, 'dropout_rate': 0.1366437223236197, 'weight_decay': 1.986548821067462e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 955.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 179\n",
      "  Learning Rate: 0.0007269039763010094\n",
      "  Dropout Rate: 0.1419805564942995\n",
      "  Weight Decay: 2.4049540136418827e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [954, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:28:55,950] Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6795\n",
      "  Elapsed time: 0:03:07.766485\n",
      "\n",
      "\n",
      "\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 179 finished with value: 0.6795 and parameters: {'learning_rate': 0.0007269039763010094, 'dropout_rate': 0.1419805564942995, 'weight_decay': 2.4049540136418827e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 954.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 180\n",
      "  Learning Rate: 0.0006966844030651582\n",
      "  Dropout Rate: 0.14558058881042135\n",
      "  Weight Decay: 2.437125359187837e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [913, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:32:15,782] Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6638\n",
      "  Elapsed time: 0:03:19.731035\n",
      "\n",
      "\n",
      "\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 180 finished with value: 0.6638 and parameters: {'learning_rate': 0.0006966844030651582, 'dropout_rate': 0.14558058881042135, 'weight_decay': 2.437125359187837e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 913.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 181\n",
      "  Learning Rate: 0.0005736606777005978\n",
      "  Dropout Rate: 0.13103355178313514\n",
      "  Weight Decay: 2.024890903420467e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [953, 10]\n",
      "\n",
      "  Accuracy: 0.6795\n",
      "  Elapsed time: 0:03:05.813117\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:35:21,943] Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 181 finished with value: 0.6795 and parameters: {'learning_rate': 0.0005736606777005978, 'dropout_rate': 0.13103355178313514, 'weight_decay': 2.024890903420467e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 182\n",
      "  Learning Rate: 0.0005845109365425994\n",
      "  Dropout Rate: 0.13913970397987618\n",
      "  Weight Decay: 2.0568429456965666e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [953, 10]\n",
      "\n",
      "  Accuracy: 0.6877\n",
      "  Elapsed time: 0:03:09.123741\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:38:31,443] Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 182 finished with value: 0.6877 and parameters: {'learning_rate': 0.0005845109365425994, 'dropout_rate': 0.13913970397987618, 'weight_decay': 2.0568429456965666e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 953.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 183\n",
      "  Learning Rate: 0.0006072085303300656\n",
      "  Dropout Rate: 0.15406681606671271\n",
      "  Weight Decay: 2.3224699549598153e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [941, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:41:41,677] Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6826\n",
      "  Elapsed time: 0:03:10.115293\n",
      "\n",
      "\n",
      "\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 183 finished with value: 0.6826 and parameters: {'learning_rate': 0.0006072085303300656, 'dropout_rate': 0.15406681606671271, 'weight_decay': 2.3224699549598153e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 941.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 184\n",
      "  Learning Rate: 0.0006117554672456398\n",
      "  Dropout Rate: 0.1554690605146553\n",
      "  Weight Decay: 2.3748744075791982e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [936, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:44:44,623] Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6844\n",
      "  Elapsed time: 0:03:02.824593\n",
      "\n",
      "\n",
      "\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 184 finished with value: 0.6844 and parameters: {'learning_rate': 0.0006117554672456398, 'dropout_rate': 0.1554690605146553, 'weight_decay': 2.3748744075791982e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 936.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 185\n",
      "  Learning Rate: 0.0007173602276686103\n",
      "  Dropout Rate: 0.15216699943285406\n",
      "  Weight Decay: 2.9626617868685683e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [877, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:47:54,310] Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6657\n",
      "  Elapsed time: 0:03:09.586645\n",
      "\n",
      "\n",
      "\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 185 finished with value: 0.6657 and parameters: {'learning_rate': 0.0007173602276686103, 'dropout_rate': 0.15216699943285406, 'weight_decay': 2.9626617868685683e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 877.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 186\n",
      "  Learning Rate: 0.0008574552749832354\n",
      "  Dropout Rate: 0.16598190676310978\n",
      "  Weight Decay: 2.5204921342883918e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [934, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:50:58,130] Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6613\n",
      "  Elapsed time: 0:03:03.709553\n",
      "\n",
      "\n",
      "\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 186 finished with value: 0.6613 and parameters: {'learning_rate': 0.0008574552749832354, 'dropout_rate': 0.16598190676310978, 'weight_decay': 2.5204921342883918e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 187\n",
      "  Learning Rate: 0.0006121922116573096\n",
      "  Dropout Rate: 0.14256256370115816\n",
      "  Weight Decay: 2.2458953759507956e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [915, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:54:11,398] Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6858\n",
      "  Elapsed time: 0:03:13.159364\n",
      "\n",
      "\n",
      "\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 187 finished with value: 0.6858 and parameters: {'learning_rate': 0.0006121922116573096, 'dropout_rate': 0.14256256370115816, 'weight_decay': 2.2458953759507956e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 188\n",
      "  Learning Rate: 0.0006237834088523068\n",
      "  Dropout Rate: 0.1580324507656911\n",
      "  Weight Decay: 2.1894922478927715e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [908, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:55:44,145] Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6392\n",
      "  Elapsed time: 0:01:32.643658\n",
      "\n",
      "\n",
      "\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 188 finished with value: 0.6392 and parameters: {'learning_rate': 0.0006237834088523068, 'dropout_rate': 0.1580324507656911, 'weight_decay': 2.1894922478927715e-05, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 908.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 189\n",
      "  Learning Rate: 0.0004996909483902031\n",
      "  Dropout Rate: 0.17545122337552843\n",
      "  Weight Decay: 2.9885401102296003e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [896, 10]\n",
      "\n",
      "  Accuracy: 0.6713\n",
      "  Elapsed time: 0:03:06.105751\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 15:58:50,628] Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 189 finished with value: 0.6713 and parameters: {'learning_rate': 0.0004996909483902031, 'dropout_rate': 0.17545122337552843, 'weight_decay': 2.9885401102296003e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 896.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 190\n",
      "  Learning Rate: 0.0004444491352886329\n",
      "  Dropout Rate: 0.1440345080416187\n",
      "  Weight Decay: 1.8199018999758313e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [926, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:02:07,033] Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6768\n",
      "  Elapsed time: 0:03:16.299746\n",
      "\n",
      "\n",
      "\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 190 finished with value: 0.6768 and parameters: {'learning_rate': 0.0004444491352886329, 'dropout_rate': 0.1440345080416187, 'weight_decay': 1.8199018999758313e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 926.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 191\n",
      "  Learning Rate: 0.0007516133157417194\n",
      "  Dropout Rate: 0.14249741312024372\n",
      "  Weight Decay: 2.478632525509597e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [939, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:05:11,164] Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.682\n",
      "  Elapsed time: 0:03:04.035767\n",
      "\n",
      "\n",
      "\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 191 finished with value: 0.682 and parameters: {'learning_rate': 0.0007516133157417194, 'dropout_rate': 0.14249741312024372, 'weight_decay': 2.478632525509597e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 192\n",
      "  Learning Rate: 0.0006112471539493197\n",
      "  Dropout Rate: 0.15382154089181038\n",
      "  Weight Decay: 2.2958847456180815e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [940, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:08:18,357] Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6766\n",
      "  Elapsed time: 0:03:07.080166\n",
      "\n",
      "\n",
      "\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 192 finished with value: 0.6766 and parameters: {'learning_rate': 0.0006112471539493197, 'dropout_rate': 0.15382154089181038, 'weight_decay': 2.2958847456180815e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 940.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 193\n",
      "  Learning Rate: 0.0009438155569522101\n",
      "  Dropout Rate: 0.12705938407256895\n",
      "  Weight Decay: 2.5608373062682057e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [918, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:11:52,251] Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6658\n",
      "  Elapsed time: 0:03:33.785752\n",
      "\n",
      "\n",
      "\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 193 finished with value: 0.6658 and parameters: {'learning_rate': 0.0009438155569522101, 'dropout_rate': 0.12705938407256895, 'weight_decay': 2.5608373062682057e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 918.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 194\n",
      "  Learning Rate: 0.0007772862358653685\n",
      "  Dropout Rate: 0.16267704128790683\n",
      "  Weight Decay: 1.8576855153965154e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [937, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:15:03,894] Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6634\n",
      "  Elapsed time: 0:03:11.530505\n",
      "\n",
      "\n",
      "\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 194 finished with value: 0.6634 and parameters: {'learning_rate': 0.0007772862358653685, 'dropout_rate': 0.16267704128790683, 'weight_decay': 1.8576855153965154e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 937.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 195\n",
      "  Learning Rate: 0.000655687755742479\n",
      "  Dropout Rate: 0.14798982195848398\n",
      "  Weight Decay: 3.47577709702614e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [894, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:18:04,827] Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6778\n",
      "  Elapsed time: 0:03:00.826701\n",
      "\n",
      "\n",
      "\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 195 finished with value: 0.6778 and parameters: {'learning_rate': 0.000655687755742479, 'dropout_rate': 0.14798982195848398, 'weight_decay': 3.47577709702614e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 894.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 196\n",
      "  Learning Rate: 0.0005046967504394427\n",
      "  Dropout Rate: 0.1350855494534307\n",
      "  Weight Decay: 2.1903401083685236e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [965, 10]\n",
      "\n",
      "  Accuracy: 0.667\n",
      "  Elapsed time: 0:01:45.987883\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:19:51,175] Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 196 finished with value: 0.667 and parameters: {'learning_rate': 0.0005046967504394427, 'dropout_rate': 0.1350855494534307, 'weight_decay': 2.1903401083685236e-05, 'num_layers': 2.0, 'batch_size': 128, 'layer-1-size': 965.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 197\n",
      "  Learning Rate: 0.001101191480859055\n",
      "  Dropout Rate: 0.18760783443959195\n",
      "  Weight Decay: 2.8189878314548937e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [939, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:23:10,972] Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6644\n",
      "  Elapsed time: 0:03:19.690344\n",
      "\n",
      "\n",
      "\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 197 finished with value: 0.6644 and parameters: {'learning_rate': 0.001101191480859055, 'dropout_rate': 0.18760783443959195, 'weight_decay': 2.8189878314548937e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 198\n",
      "  Learning Rate: 0.0007846633602073159\n",
      "  Dropout Rate: 0.12363299131658406\n",
      "  Weight Decay: 1.7762795666116574e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 64\n",
      "  Layer Sizes: [830, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:25:27,895] Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6674\n",
      "  Elapsed time: 0:02:16.822086\n",
      "\n",
      "\n",
      "\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 198 finished with value: 0.6674 and parameters: {'learning_rate': 0.0007846633602073159, 'dropout_rate': 0.12363299131658406, 'weight_decay': 1.7762795666116574e-05, 'num_layers': 2.0, 'batch_size': 64, 'layer-1-size': 830.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 199\n",
      "  Learning Rate: 0.0005549237858850183\n",
      "  Dropout Rate: 0.14146910542703647\n",
      "  Weight Decay: 2.0406743842170775e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [915, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:28:47,135] Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6739\n",
      "  Elapsed time: 0:03:19.127978\n",
      "\n",
      "\n",
      "\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 199 finished with value: 0.6739 and parameters: {'learning_rate': 0.0005549237858850183, 'dropout_rate': 0.14146910542703647, 'weight_decay': 2.0406743842170775e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 915.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 200\n",
      "  Learning Rate: 0.0013974241945165116\n",
      "  Dropout Rate: 0.11323724435379638\n",
      "  Weight Decay: 0.009821352446890644\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 16\n",
      "  Layer Sizes: [880, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:34:20,031] Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.5769\n",
      "  Elapsed time: 0:05:32.747372\n",
      "\n",
      "\n",
      "\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 200 finished with value: 0.5769 and parameters: {'learning_rate': 0.0013974241945165116, 'dropout_rate': 0.11323724435379638, 'weight_decay': 0.009821352446890644, 'num_layers': 2.0, 'batch_size': 16, 'layer-1-size': 880.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 201\n",
      "  Learning Rate: 0.0006977009508398617\n",
      "  Dropout Rate: 0.139965977777996\n",
      "  Weight Decay: 2.7033270254729257e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [956, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:37:35,407] Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6737\n",
      "  Elapsed time: 0:03:15.259650\n",
      "\n",
      "\n",
      "\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 201 finished with value: 0.6737 and parameters: {'learning_rate': 0.0006977009508398617, 'dropout_rate': 0.139965977777996, 'weight_decay': 2.7033270254729257e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 956.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 202\n",
      "  Learning Rate: 0.0008197106062084282\n",
      "  Dropout Rate: 0.14921489786345365\n",
      "  Weight Decay: 2.4389500715838387e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [948, 10]\n",
      "\n",
      "  Accuracy: 0.6782\n",
      "  Elapsed time: 0:03:16.855594\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:40:52,614] Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 202 finished with value: 0.6782 and parameters: {'learning_rate': 0.0008197106062084282, 'dropout_rate': 0.14921489786345365, 'weight_decay': 2.4389500715838387e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 948.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 203\n",
      "  Learning Rate: 0.000685079274746762\n",
      "  Dropout Rate: 0.13441833702118317\n",
      "  Weight Decay: 2.3289316909814363e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [960, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:44:04,022] Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6771\n",
      "  Elapsed time: 0:03:11.295809\n",
      "\n",
      "\n",
      "\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 203 finished with value: 0.6771 and parameters: {'learning_rate': 0.000685079274746762, 'dropout_rate': 0.13441833702118317, 'weight_decay': 2.3289316909814363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 960.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 204\n",
      "  Learning Rate: 0.0006160398184467423\n",
      "  Dropout Rate: 0.1544153908089344\n",
      "  Weight Decay: 3.023235258173217e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [930, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:47:17,782] Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6566\n",
      "  Elapsed time: 0:03:13.648435\n",
      "\n",
      "\n",
      "\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 204 finished with value: 0.6566 and parameters: {'learning_rate': 0.0006160398184467423, 'dropout_rate': 0.1544153908089344, 'weight_decay': 3.023235258173217e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 930.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 205\n",
      "  Learning Rate: 0.000883887326681663\n",
      "  Dropout Rate: 0.1686991799841235\n",
      "  Weight Decay: 1.9685250565355992e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [968, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:50:26,284] Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6828\n",
      "  Elapsed time: 0:03:08.397461\n",
      "\n",
      "\n",
      "\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 205 finished with value: 0.6828 and parameters: {'learning_rate': 0.000883887326681663, 'dropout_rate': 0.1686991799841235, 'weight_decay': 1.9685250565355992e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 206\n",
      "  Learning Rate: 0.0009871343916755223\n",
      "  Dropout Rate: 0.17220866010654753\n",
      "  Weight Decay: 0.00031524512688423665\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [973, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:54:15,931] Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6776\n",
      "  Elapsed time: 0:03:49.520368\n",
      "\n",
      "\n",
      "\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 206 finished with value: 0.6776 and parameters: {'learning_rate': 0.0009871343916755223, 'dropout_rate': 0.17220866010654753, 'weight_decay': 0.00031524512688423665, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 973.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 207\n",
      "  Learning Rate: 0.0012128034930189472\n",
      "  Dropout Rate: 0.1634919486178296\n",
      "  Weight Decay: 1.7650462399975405e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [914, 10]\n",
      "\n",
      "  Accuracy: 0.6781\n",
      "  Elapsed time: 0:03:27.346160\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 16:57:43,635] Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 207 finished with value: 0.6781 and parameters: {'learning_rate': 0.0012128034930189472, 'dropout_rate': 0.1634919486178296, 'weight_decay': 1.7650462399975405e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 914.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 208\n",
      "  Learning Rate: 0.0008720111533632408\n",
      "  Dropout Rate: 0.10456441152560064\n",
      "  Weight Decay: 1.492130274006926e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [983, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:01:00,609] Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6699\n",
      "  Elapsed time: 0:03:16.863792\n",
      "\n",
      "\n",
      "\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 208 finished with value: 0.6699 and parameters: {'learning_rate': 0.0008720111533632408, 'dropout_rate': 0.10456441152560064, 'weight_decay': 1.492130274006926e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 209\n",
      "  Learning Rate: 0.00046092910134945867\n",
      "  Dropout Rate: 0.1243554492906085\n",
      "  Weight Decay: 1.9470047891963363e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [945, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:04:14,902] Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6747\n",
      "  Elapsed time: 0:03:14.191103\n",
      "\n",
      "\n",
      "\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 209 finished with value: 0.6747 and parameters: {'learning_rate': 0.00046092910134945867, 'dropout_rate': 0.1243554492906085, 'weight_decay': 1.9470047891963363e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 210\n",
      "  Learning Rate: 0.0005821175937313596\n",
      "  Dropout Rate: 0.1795885878220232\n",
      "  Weight Decay: 1.634643713514514e-05\n",
      "  Number of Layers: 5\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [969, 266, 412, 459, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:05:59,620] Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6568\n",
      "  Elapsed time: 0:01:44.603231\n",
      "\n",
      "\n",
      "\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 210 finished with value: 0.6568 and parameters: {'learning_rate': 0.0005821175937313596, 'dropout_rate': 0.1795885878220232, 'weight_decay': 1.634643713514514e-05, 'num_layers': 5.0, 'batch_size': 256, 'layer-1-size': 969.0, 'layer-2-size': 266.0, 'layer-3-size': 412.0, 'layer-4-size': 459.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 211\n",
      "  Learning Rate: 0.0007407815402981088\n",
      "  Dropout Rate: 0.14284328933545398\n",
      "  Weight Decay: 2.269048452525512e-05\n",
      "  Number of Layers: 6\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [956, 390, 173, 737, 897, 10]\n",
      "\n",
      "  Accuracy: 0.6531\n",
      "  Elapsed time: 0:09:57.063056\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:15:57,039] Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 211 finished with value: 0.6531 and parameters: {'learning_rate': 0.0007407815402981088, 'dropout_rate': 0.14284328933545398, 'weight_decay': 2.269048452525512e-05, 'num_layers': 6.0, 'batch_size': 32, 'layer-1-size': 956.0, 'layer-2-size': 390.0, 'layer-3-size': 173.0, 'layer-4-size': 737.0, 'layer-5-size': 897.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 212\n",
      "  Learning Rate: 0.000753677808115097\n",
      "  Dropout Rate: 0.16085065197568235\n",
      "  Weight Decay: 2.475061867817097e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [934, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:19:17,038] Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6737\n",
      "  Elapsed time: 0:03:19.880888\n",
      "\n",
      "\n",
      "\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 212 finished with value: 0.6737 and parameters: {'learning_rate': 0.000753677808115097, 'dropout_rate': 0.16085065197568235, 'weight_decay': 2.475061867817097e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 934.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 213\n",
      "  Learning Rate: 0.0008982237147947116\n",
      "  Dropout Rate: 0.132706530946894\n",
      "  Weight Decay: 2.0597994332718867e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [957, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:22:36,952] Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.668\n",
      "  Elapsed time: 0:03:19.808021\n",
      "\n",
      "\n",
      "\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 213 finished with value: 0.668 and parameters: {'learning_rate': 0.0008982237147947116, 'dropout_rate': 0.132706530946894, 'weight_decay': 2.0597994332718867e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 214\n",
      "  Learning Rate: 0.0006501674722668426\n",
      "  Dropout Rate: 0.15027463725554954\n",
      "  Weight Decay: 2.6260063098928324e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [924, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:25:48,662] Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6652\n",
      "  Elapsed time: 0:03:11.591512\n",
      "\n",
      "\n",
      "\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 214 finished with value: 0.6652 and parameters: {'learning_rate': 0.0006501674722668426, 'dropout_rate': 0.15027463725554954, 'weight_decay': 2.6260063098928324e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 924.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 215\n",
      "  Learning Rate: 0.0004126494915489284\n",
      "  Dropout Rate: 0.11977572418618551\n",
      "  Weight Decay: 3.29607513859969e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [986, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:29:06,545] Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6723\n",
      "  Elapsed time: 0:03:17.725854\n",
      "\n",
      "\n",
      "\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 215 finished with value: 0.6723 and parameters: {'learning_rate': 0.0004126494915489284, 'dropout_rate': 0.11977572418618551, 'weight_decay': 3.29607513859969e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 986.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 216\n",
      "  Learning Rate: 0.0005178858053192154\n",
      "  Dropout Rate: 0.09752777364421439\n",
      "  Weight Decay: 1.4061568984116561e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [968, 10]\n",
      "\n",
      "  Accuracy: 0.6688\n",
      "  Elapsed time: 0:03:09.656032\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:32:17,682] Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 216 finished with value: 0.6688 and parameters: {'learning_rate': 0.0005178858053192154, 'dropout_rate': 0.09752777364421439, 'weight_decay': 1.4061568984116561e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 217\n",
      "  Learning Rate: 0.0009919803245150521\n",
      "  Dropout Rate: 0.11111551285836589\n",
      "  Weight Decay: 2.104222139468528e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [943, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:35:43,799] Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6802\n",
      "  Elapsed time: 0:03:26.003371\n",
      "\n",
      "\n",
      "\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 217 finished with value: 0.6802 and parameters: {'learning_rate': 0.0009919803245150521, 'dropout_rate': 0.11111551285836589, 'weight_decay': 2.104222139468528e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 218\n",
      "  Learning Rate: 0.001049505050668083\n",
      "  Dropout Rate: 0.46984650600168065\n",
      "  Weight Decay: 1.885339073963355e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [902, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:38:53,969] Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.593\n",
      "  Elapsed time: 0:03:10.059340\n",
      "\n",
      "\n",
      "\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 218 finished with value: 0.593 and parameters: {'learning_rate': 0.001049505050668083, 'dropout_rate': 0.46984650600168065, 'weight_decay': 1.885339073963355e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 902.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 219\n",
      "  Learning Rate: 0.001231305348254984\n",
      "  Dropout Rate: 0.10991238902470983\n",
      "  Weight Decay: 1.662369252787251e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [943, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:42:20,273] Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6786\n",
      "  Elapsed time: 0:03:26.202193\n",
      "\n",
      "\n",
      "\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 219 finished with value: 0.6786 and parameters: {'learning_rate': 0.001231305348254984, 'dropout_rate': 0.10991238902470983, 'weight_decay': 1.662369252787251e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 943.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 220\n",
      "  Learning Rate: 0.0008870612074628996\n",
      "  Dropout Rate: 0.075965024040362\n",
      "  Weight Decay: 2.0553192736704663e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [923, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:45:36,356] Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.675\n",
      "  Elapsed time: 0:03:15.982495\n",
      "\n",
      "\n",
      "\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 220 finished with value: 0.675 and parameters: {'learning_rate': 0.0008870612074628996, 'dropout_rate': 0.075965024040362, 'weight_decay': 2.0553192736704663e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 221\n",
      "  Learning Rate: 0.0007123659121888222\n",
      "  Dropout Rate: 0.13118892958293282\n",
      "  Weight Decay: 2.3106884845585307e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [754, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:48:41,827] Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.672\n",
      "  Elapsed time: 0:03:05.363320\n",
      "\n",
      "\n",
      "\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 221 finished with value: 0.672 and parameters: {'learning_rate': 0.0007123659121888222, 'dropout_rate': 0.13118892958293282, 'weight_decay': 2.3106884845585307e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 754.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 222\n",
      "  Learning Rate: 0.000583016656356341\n",
      "  Dropout Rate: 0.14197102429604064\n",
      "  Weight Decay: 2.6868911242018184e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [951, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:51:53,111] Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6902\n",
      "  Elapsed time: 0:03:11.180571\n",
      "\n",
      "\n",
      "\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 222 finished with value: 0.6902 and parameters: {'learning_rate': 0.000583016656356341, 'dropout_rate': 0.14197102429604064, 'weight_decay': 2.6868911242018184e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 951.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 223\n",
      "  Learning Rate: 0.0006151844141178043\n",
      "  Dropout Rate: 0.11775708041124669\n",
      "  Weight Decay: 2.7906507854057456e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [939, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:55:06,796] Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6873\n",
      "  Elapsed time: 0:03:13.573970\n",
      "\n",
      "\n",
      "\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 223 finished with value: 0.6873 and parameters: {'learning_rate': 0.0006151844141178043, 'dropout_rate': 0.11775708041124669, 'weight_decay': 2.7906507854057456e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 939.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 224\n",
      "  Learning Rate: 0.0005995731861118942\n",
      "  Dropout Rate: 0.11989528886537801\n",
      "  Weight Decay: 4.010136306511602e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [970, 10]\n",
      "\n",
      "  Accuracy: 0.6743\n",
      "  Elapsed time: 0:03:21.952727\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 17:58:29,108] Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 224 finished with value: 0.6743 and parameters: {'learning_rate': 0.0005995731861118942, 'dropout_rate': 0.11989528886537801, 'weight_decay': 4.010136306511602e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 970.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 225\n",
      "  Learning Rate: 0.00053120049465673\n",
      "  Dropout Rate: 0.15672994191434453\n",
      "  Weight Decay: 3.086546406193339e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [933, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:01:37,560] Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6763\n",
      "  Elapsed time: 0:03:08.348080\n",
      "\n",
      "\n",
      "\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 225 finished with value: 0.6763 and parameters: {'learning_rate': 0.00053120049465673, 'dropout_rate': 0.15672994191434453, 'weight_decay': 3.086546406193339e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 933.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 226\n",
      "  Learning Rate: 0.00045945062944506473\n",
      "  Dropout Rate: 0.12827348778655603\n",
      "  Weight Decay: 2.6003823711825445e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [989, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:04:52,793] Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6811\n",
      "  Elapsed time: 0:03:15.130655\n",
      "\n",
      "\n",
      "\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 226 finished with value: 0.6811 and parameters: {'learning_rate': 0.00045945062944506473, 'dropout_rate': 0.12827348778655603, 'weight_decay': 2.6003823711825445e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 989.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 227\n",
      "  Learning Rate: 0.00047167139547857627\n",
      "  Dropout Rate: 0.1420500718932568\n",
      "  Weight Decay: 2.7517055665380638e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [998, 464, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:09:21,141] Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6713\n",
      "  Elapsed time: 0:04:28.247392\n",
      "\n",
      "\n",
      "\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 227 finished with value: 0.6713 and parameters: {'learning_rate': 0.00047167139547857627, 'dropout_rate': 0.1420500718932568, 'weight_decay': 2.7517055665380638e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 998.0, 'layer-2-size': 464.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 228\n",
      "  Learning Rate: 0.0004167284652644871\n",
      "  Dropout Rate: 0.12747592340355882\n",
      "  Weight Decay: 2.6552952528340216e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [983, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:12:26,711] Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6789\n",
      "  Elapsed time: 0:03:05.456633\n",
      "\n",
      "\n",
      "\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 228 finished with value: 0.6789 and parameters: {'learning_rate': 0.0004167284652644871, 'dropout_rate': 0.12747592340355882, 'weight_decay': 2.6552952528340216e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 983.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 229\n",
      "  Learning Rate: 0.0005621205753323715\n",
      "  Dropout Rate: 0.1694654225798112\n",
      "  Weight Decay: 1.316110462459347e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [994, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:15:31,931] Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6748\n",
      "  Elapsed time: 0:03:05.111400\n",
      "\n",
      "\n",
      "\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 229 finished with value: 0.6748 and parameters: {'learning_rate': 0.0005621205753323715, 'dropout_rate': 0.1694654225798112, 'weight_decay': 1.316110462459347e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 994.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 230\n",
      "  Learning Rate: 0.00047605088258317657\n",
      "  Dropout Rate: 0.149464351787582\n",
      "  Weight Decay: 1.772286174989471e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [965, 359, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:19:24,726] Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6802\n",
      "  Elapsed time: 0:03:52.658181\n",
      "\n",
      "\n",
      "\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 230 finished with value: 0.6802 and parameters: {'learning_rate': 0.00047605088258317657, 'dropout_rate': 0.149464351787582, 'weight_decay': 1.772286174989471e-05, 'num_layers': 3.0, 'batch_size': 32, 'layer-1-size': 965.0, 'layer-2-size': 359.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 231\n",
      "  Learning Rate: 0.0006445711744105692\n",
      "  Dropout Rate: 0.10060469840736774\n",
      "  Weight Decay: 3.114353399079598e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [945, 10]\n",
      "\n",
      "  Accuracy: 0.6757\n",
      "  Elapsed time: 0:03:10.797561\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:22:35,885] Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 231 finished with value: 0.6757 and parameters: {'learning_rate': 0.0006445711744105692, 'dropout_rate': 0.10060469840736774, 'weight_decay': 3.114353399079598e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 945.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 232\n",
      "  Learning Rate: 0.008117232994465049\n",
      "  Dropout Rate: 0.13007448884154685\n",
      "  Weight Decay: 3.762098038552241e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [923, 10]\n",
      "\n",
      "  Accuracy: 0.6287\n",
      "  Elapsed time: 0:04:57.497281\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:27:33,755] Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 232 finished with value: 0.6287 and parameters: {'learning_rate': 0.008117232994465049, 'dropout_rate': 0.13007448884154685, 'weight_decay': 3.762098038552241e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 923.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 233\n",
      "  Learning Rate: 0.0006049107651235596\n",
      "  Dropout Rate: 0.11601016593988311\n",
      "  Weight Decay: 2.401685272584946e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [957, 10]\n",
      "\n",
      "  Accuracy: 0.6758\n",
      "  Elapsed time: 0:03:20.087628\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:30:54,220] Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 233 finished with value: 0.6758 and parameters: {'learning_rate': 0.0006049107651235596, 'dropout_rate': 0.11601016593988311, 'weight_decay': 2.401685272584946e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 957.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 234\n",
      "  Learning Rate: 0.00038455411778583556\n",
      "  Dropout Rate: 0.061959065604230014\n",
      "  Weight Decay: 2.632175711138509e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [909, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:34:14,693] Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6711\n",
      "  Elapsed time: 0:03:20.364603\n",
      "\n",
      "\n",
      "\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 234 finished with value: 0.6711 and parameters: {'learning_rate': 0.00038455411778583556, 'dropout_rate': 0.061959065604230014, 'weight_decay': 2.632175711138509e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 909.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 235\n",
      "  Learning Rate: 0.0005404353327639524\n",
      "  Dropout Rate: 0.1384523119346136\n",
      "  Weight Decay: 1.9966181744466277e-05\n",
      "  Number of Layers: 10\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [977, 222, 299, 929, 457, 362, 346, 624, 97, 10]\n",
      "\n",
      "  Accuracy: 0.6191\n",
      "  Elapsed time: 0:12:59.560498\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:47:14,619] Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 235 finished with value: 0.6191 and parameters: {'learning_rate': 0.0005404353327639524, 'dropout_rate': 0.1384523119346136, 'weight_decay': 1.9966181744466277e-05, 'num_layers': 10.0, 'batch_size': 32, 'layer-1-size': 977.0, 'layer-2-size': 222.0, 'layer-3-size': 299.0, 'layer-4-size': 929.0, 'layer-5-size': 457.0, 'layer-6-size': 362.0, 'layer-7-size': 346.0, 'layer-8-size': 624.0, 'layer-9-size': 97.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 236\n",
      "  Learning Rate: 0.0007957233411390797\n",
      "  Dropout Rate: 0.12242405457450241\n",
      "  Weight Decay: 0.00015767799459146745\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 256\n",
      "  Layer Sizes: [946, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:48:56,880] Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6675\n",
      "  Elapsed time: 0:01:42.148811\n",
      "\n",
      "\n",
      "\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 236 finished with value: 0.6675 and parameters: {'learning_rate': 0.0007957233411390797, 'dropout_rate': 0.12242405457450241, 'weight_decay': 0.00015767799459146745, 'num_layers': 2.0, 'batch_size': 256, 'layer-1-size': 946.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 237\n",
      "  Learning Rate: 0.0006561405934444627\n",
      "  Dropout Rate: 0.15658217822554646\n",
      "  Weight Decay: 2.9337703643160692e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [996, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:52:47,974] Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6838\n",
      "  Elapsed time: 0:03:50.979051\n",
      "\n",
      "\n",
      "\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 237 finished with value: 0.6838 and parameters: {'learning_rate': 0.0006561405934444627, 'dropout_rate': 0.15658217822554646, 'weight_decay': 2.9337703643160692e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 996.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 238\n",
      "  Learning Rate: 0.0006666468696462815\n",
      "  Dropout Rate: 0.16110703624223593\n",
      "  Weight Decay: 2.9750091835975048e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [1002, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 18:56:34,489] Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.679\n",
      "  Elapsed time: 0:03:46.401232\n",
      "\n",
      "\n",
      "\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 238 finished with value: 0.679 and parameters: {'learning_rate': 0.0006666468696462815, 'dropout_rate': 0.16110703624223593, 'weight_decay': 2.9750091835975048e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 1002.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 239\n",
      "  Learning Rate: 0.002456220325967233\n",
      "  Dropout Rate: 0.15284123755368412\n",
      "  Weight Decay: 0.002492836606853909\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [985, 10]\n",
      "\n",
      "  Accuracy: 0.619\n",
      "  Elapsed time: 0:05:20.409730\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 19:01:55,258] Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 239 finished with value: 0.619 and parameters: {'learning_rate': 0.002456220325967233, 'dropout_rate': 0.15284123755368412, 'weight_decay': 0.002492836606853909, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 985.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 240\n",
      "  Learning Rate: 0.0004901244663816102\n",
      "  Dropout Rate: 0.1432857002640986\n",
      "  Weight Decay: 2.2401923754113297e-05\n",
      "  Number of Layers: 3\n",
      "  Batch Size: 128\n",
      "  Layer Sizes: [1005, 287, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-01 19:04:07,209] Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Accuracy: 0.6579\n",
      "  Elapsed time: 0:02:11.847280\n",
      "\n",
      "\n",
      "\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Trial 240 finished with value: 0.6579 and parameters: {'learning_rate': 0.0004901244663816102, 'dropout_rate': 0.1432857002640986, 'weight_decay': 2.2401923754113297e-05, 'num_layers': 3.0, 'batch_size': 128, 'layer-1-size': 1005.0, 'layer-2-size': 287.0}. Best is trial 84 with value: 0.6923.\n",
      "Hyperparameters of trial number 241\n",
      "  Learning Rate: 0.0006216284066704859\n",
      "  Dropout Rate: 0.08278753167707956\n",
      "  Weight Decay: 3.5567834124304784e-05\n",
      "  Number of Layers: 2\n",
      "  Batch Size: 32\n",
      "  Layer Sizes: [968, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-11-01 19:05:06,224] Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n",
      "Trial 241 failed with parameters: {'learning_rate': 0.0006216284066704859, 'dropout_rate': 0.08278753167707956, 'weight_decay': 3.5567834124304784e-05, 'num_layers': 2.0, 'batch_size': 32, 'layer-1-size': 968.0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3722706538.py\", line 27, in objective\n",
      "    accuracy = train_and_eval(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadet\\AppData\\Local\\Temp\\ipykernel_2125232\\3817530194.py\", line 29, in train_and_eval\n",
      "    for inputs, labels in train_loader:\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 439, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 387, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1040, in __init__\n",
      "    w.start()\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "                  ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py\", line 336, in _Popen\n",
      "    return Popen(process_obj)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 95, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"c:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-11-01 19:05:06,233] Trial 241 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 241 failed with value None.\n",
      "Trial 241 failed with value None.\n",
      "Trial 241 failed with value None.\n",
      "Trial 241 failed with value None.\n",
      "Trial 241 failed with value None.\n",
      "Trial 241 failed with value None.\n",
      "Trial 241 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 52\u001b[0m\n\u001b[0;32m     48\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage_name, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Uruchomienie Optuna i konfiguracja badań\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# study = optuna.create_study(direction='maximize')\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Najlepsze konfiguracje hiperparametrów\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNajlepsze hiperparametry: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[63], line 27\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Layer Sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_sizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Trening modelu z hiperparametrami\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[58], line 29\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[1;34m(learning_rate, num_layers, layer_sizes, batch_size, dropout_rate, weight_decay)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     28\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Przepuszczenie danych przez sieć, obliczenie funkcji kosztu i wstecznej propagacji\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kadet\\miniconda3\\envs\\MRO\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-2, log=True)\n",
    "    num_layers = int(trial.suggest_float(\"num_layers\", 2.0, 10.0, step=1.0, log=False))\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256])\n",
    "\n",
    "    layer_sizes = []\n",
    "    layer_sizes.append(int(trial.suggest_float(\"layer-1-size\", 128, 1024, step=1.0, log=False)))\n",
    "    for i in range(1, num_layers-1):\n",
    "      name = \"layer-{}-size\".format(i+1)\n",
    "      layer_sizes.append(int(trial.suggest_float(name, 64, 1024, step=1.0, log=False)))\n",
    "\n",
    "    layer_sizes.append(10)\n",
    "\n",
    "    print(f\"Hyperparameters of trial number {trial.number}\")\n",
    "    print(f\"  Learning Rate: {learning_rate}\")\n",
    "    print(f\"  Dropout Rate: {dropout_rate}\")\n",
    "    print(f\"  Weight Decay: {weight_decay}\")\n",
    "    print(f\"  Number of Layers: {num_layers}\")\n",
    "    print(f\"  Batch Size: {batch_size}\")\n",
    "    print(f\"  Layer Sizes: {layer_sizes}\")\n",
    "\n",
    "    # Trening modelu z hiperparametrami\n",
    "    accuracy = train_and_eval(\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        layer_sizes,\n",
    "        batch_size,\n",
    "        dropout_rate,\n",
    "        weight_decay\n",
    "    )\n",
    "    print()\n",
    "    print(f\"  Accuracy: {accuracy}\")\n",
    "    print(f\"  Elapsed time: {datetime.datetime.now() - trial.datetime_start}\")\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"mro-kadet-04\"\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"maximize\")\n",
    "\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "print(\"Najlepsze hiperparametry: \", study.best_params)\n",
    "print(\"Najlepsza dokładność: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def classify_and_display_images(model, test_loader, num_images=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    images, true_labels, predicted_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test images\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Store images, true labels, and predicted labels\n",
    "            images.extend(inputs.cpu())\n",
    "            true_labels.extend(labels.cpu())\n",
    "            predicted_labels.extend(preds.cpu())\n",
    "\n",
    "            # Stop after getting the desired number of images\n",
    "            if len(images) >= num_images:\n",
    "                break\n",
    "\n",
    "    # Display each image with true and predicted labels\n",
    "    plt.figure(figsize=(10, 2 * num_images))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].numpy().transpose((1, 2, 0))  # CHW to HWC\n",
    "        img = np.clip(img * np.array([0.2023, 0.1994, 0.2010]) + \n",
    "                      np.array([0.4914, 0.4822, 0.4465]), 0, 1)  # Unnormalize\n",
    "        true_label = class_names[true_labels[i]]\n",
    "        predicted_label = class_names[predicted_labels[i]]\n",
    "\n",
    "        # Plot each image\n",
    "        ax = plt.subplot(num_images, 1, i + 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"True: {true_label} | Predicted: {predicted_label}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15, elapsed time: 0:00:56.825123\n",
      "epoch 2/15, elapsed time: 0:01:53.096776\n",
      "epoch 3/15, elapsed time: 0:02:49.390968\n",
      "epoch 4/15, elapsed time: 0:08:35.491159\n",
      "epoch 5/15, elapsed time: 0:09:31.368102\n",
      "epoch 6/15, elapsed time: 0:10:27.813113\n",
      "epoch 7/15, elapsed time: 0:11:21.799644\n",
      "epoch 8/15, elapsed time: 0:12:16.969020\n",
      "epoch 9/15, elapsed time: 0:13:33.861111\n",
      "epoch 10/15, elapsed time: 0:14:30.860676\n",
      "epoch 11/15, elapsed time: 0:15:29.242504\n",
      "epoch 12/15, elapsed time: 0:16:26.483627\n",
      "epoch 13/15, elapsed time: 0:17:23.854069\n",
      "epoch 14/15, elapsed time: 0:18:22.572979\n",
      "epoch 15/15, elapsed time: 0:19:22.420694\n"
     ]
    }
   ],
   "source": [
    "acc, nn = train_and_eval(0.00032612430218809, 2, [943, 10], 32, 0.0652566450453942, 1.35021744016308e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6896\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def classify_and_display_images(model, test_loader, num_images=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    images, true_labels, predicted_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test images\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Store images, true labels, and predicted labels\n",
    "            images.extend(inputs.cpu())\n",
    "            true_labels.extend(labels.cpu())\n",
    "            predicted_labels.extend(preds.cpu())\n",
    "\n",
    "            # Stop after getting the desired number of images\n",
    "            if len(images) >= num_images:\n",
    "                break\n",
    "\n",
    "    # Display each image with true and predicted labels\n",
    "    plt.figure(figsize=(10, 2 * num_images))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].numpy().transpose((1, 2, 0))  # CHW to HWC\n",
    "        img = np.clip(img * np.array([0.2023, 0.1994, 0.2010]) + \n",
    "                      np.array([0.4914, 0.4822, 0.4465]), 0, 1)  # Unnormalize\n",
    "        true_label = class_names[true_labels[i]]\n",
    "        predicted_label = class_names[predicted_labels[i]]\n",
    "\n",
    "        # Plot each image\n",
    "        ax = plt.subplot(num_images, 1, i + 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"True: {true_label} | Predicted: {predicted_label}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "    \n",
    "classify_and_display_images(nn, test_loader, 5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
