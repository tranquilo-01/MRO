{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Augmentacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cifar_trainset = CIFAR10(root='./data', train=True, download=False)\n",
    "data = cifar_trainset.data / 255\n",
    "\n",
    "mean = data.mean(axis=(0, 1, 2))\n",
    "std = data.std(axis=(0, 1, 2))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(size=32, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2, 3 - przypięcie augmentacji, załadowanie cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True,\n",
    "                        transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                          shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = CIFAR10(root='./data', train=False,\n",
    "                       transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,\n",
    "                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4, 5 - Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def image_to_patches(images, patch_size):\n",
    "    batch_size, channels, height, width = images.size()\n",
    "    assert height % patch_size == 0 and width % patch_size == 0, \"Image size must be divisible by patch size\"\n",
    "\n",
    "    patches = images.unfold(2, patch_size, patch_size).unfold(\n",
    "        3, patch_size, patch_size)\n",
    "    patches = patches.contiguous().view(\n",
    "        batch_size, channels, -1, patch_size, patch_size)\n",
    "    # (batch_size, num_patches, channels, patch_size, patch_size)\n",
    "    patches = patches.permute(0, 2, 1, 3, 4)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, _ = next(data_iter)\n",
    "patches = image_to_patches(images, patch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "images, _ = next(data_iter)\n",
    "patches = image_to_patches(images, patch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_patches(img):\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        patch = img[i].permute(1, 2, 0)\n",
    "        ax.imshow((patch * torch.tensor(std) + torch.tensor(mean)).numpy())\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAJ8CAYAAACP2sdVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkEElEQVR4nO3dabDleVkf8Oesd+2+fW+vs/QszMCADIuooIgkYgiUqZQKJsZolURZSlFUFBAIoUQyCkoiGGMgmmhcggllJFRZlZSaaCm7gA7DMgzMvvRyu2/f/Z57lrzxhS+GmnP/T9d0pZ7P5/X/e37fPvcs3/N/063JZDIJAABKaF/pAgAAPH6MPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCutNe+F0/8fOpgwaDUSofEbE22EvlO518hz9/720HzrzoR96YOrPbaqXyERHt3kwu359Nd/jgO99w4MyL3vALqTMv7myn8hERe+1OKj/q99MdPvvOg7+GnvL6d6bO7Lby//nP4dncv70b+df+n/3sTzTKfdPPvCN17mg4TOUjIg51eqn80cW5dIf/9pYfO3Dmm3/84J+Tf9fd57ZS+YiIyUzuuRtchtf/6n/62QNnTr06975dPrqcykdErKwcTuXnZvKfeX/8w9914Mw/eO//SJ25fxn+5vvJh2i1ct83ERF/+crveMxr3PkDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAopDvthVcdX0kddO78xVQ+ImJnfyeVn+l10h2amJ/ppfLtyTjdYTIZpvKt4SDdoYnDrVy+NzeX7rAxHqXy+1foJ9ZSTFL51jiXj4iY38+9druTK/f7dDb5kt8aJV+8EbGXzA+G+c+OJhbmZ1P55cP5196kl/vc3Rpfmedufzf3V794Lv9d203+02eOHUl3aHRuK/cd382/ZSNauSdv1LocJR6bO38AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIV0p71wrj/1pY9qe+NSKh8RcezQfCp/3clj6Q5N3LByJJW/cGkt3WF9by+V3xhspzs0sbZ2IZXv9XOvmYiImXbuN9LcKF2hke7mZio/HO6nOww6uc+N8fjK/T7dWc19Zm2PJ+kOw/nZXIcr9PRl3zNLc/18iW7utdfZy7/+m5ht5Z67wd4g3WF1dTWVHw520x2auLSWe88uHTmU7rDQy/39RuNxusM03PkDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAopDvtheceeih10ObGRiofEXHdqeOp/Onjy+kOTZxcOZR7gOF2ukN7MsxVmIzSHZrY2R/k8rl4RES0k7+RlmZm8iUamBnup/Kd1jjdoRu5x9jb3U13aGrj0qVcfn+S7tDZ3knlW4P8Z0cTu8nevctwX2K2N/XX26Ma7uXeP03NTHLvmcvxSb2/n/u3r66vX4YWB/fQmXOp/CD5mRkRsbKc+76fn5tNd5iGO38AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIW0JpPJ5EqXAADg8eHOHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHdaS98ySvekDro/IX1VD4i4omnT6XyT73lunSH1/7wvzhw5j2/+Z9TZ66dv5DKR0SsnV1L5R/Z2kl3+L1f/aUDZ771h16TOnNnP//7pj2cpPInDi+kO/zhf7jtwJnv/JE3ps4cxjiVj4gYJh9ibT3/uvvo772nUe4JL3pZ6tyNnfzzF91eKj4/20lXuPeP3nfgzK3f+5OpM+eXllL5iIgTKyup/Pp2/rX357988O/NW1/1c6kzty7Dy257lHuQYSvfYfU33nrgzPFXvD115ky/n8pHRBxZWszllw+nO/zF677/Ma9x5w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgkO60F+7sD1MHDQa5fETEhUfOpvKby7PpDk3MTCap/NJCvvdmO9dhPNhOd2hiMdm708l3WN/L/dv3BqN8iSaSf7PJfr73cNJK5ceD/XSHxka5f/9keBn+7sPc87c/Huc7NHDx0mYqv3cZXntzkXvuOv1+ukMTc71cfryf/5uPk8//XvK5b6o9zp072Mt930REnLmwm8pf2spvpWm48wcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUEh32gsvbeykDhqNRql8RMTG+noqv3nfg+kOTYwuXErl+0uH0x3ai3Op/Gh1P92hie5gkMq3Jp10h8FgN5XfaOVf+01sbeV6T6KV7rA/yeX7nXyHplYOL6TyvX7+PbOzlXvtjC/D526jcwe5f/vOOP93P79/PpVfOJ7/3G1ivj9O5U8u9tMddpMv3fO7uX9DU4u9qSfNo9qPXrrD9jD3obc13Et3mIY7fwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIV0p71wfzBKHTQZjVP5iIj9ca7DpQcfSndoYvjAI6n8ysLhdIcTh5ZS+XMLC+kOTYwnudfNIPm6jYhoDXMd5mZ76Q6Nzu1O/fZ+VMNopTvsD4epfLud79DU/NxsKt/uzaQ79NuDVH53Zy/doYneJPe+G0/20x3Ge5NU/njvaLpDEy+69amp/BOvvzrd4b7zl1L5/3vH3ekOTXRbub/5OPI7pTXOfeY9Xp947vwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABTSmkwmkytdAgCAx4c7fwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIV0p73wG/7RK1MHTYaDVD4iYjb2U/mbti6mO/zWX/zRgTP/5nteljrzumfemspHROwsL6Xynz9zNt3htre++cCZl778R1Jnnlm9lMpHRMSglYqfWF5OV/iD3/mVA2e+7+U/njpzPyapfETEhZ3ce3Z7mK4QH/79X2uUe+73viZ17jg6qXxExGA/9wS0I/fajYj45Afec+DMs1/6w6kztzbXU/mIiNNLR1P5F/6956Y7/NSr/9mBM3/18TtTZy4nP+sjIv7iC19K5f/7hz+d7vChn/+xA2duesXbU2futS/He3acyre6U8+yr+rM+97wmNe48wcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFBId9oLZ/q91EGDyTCVj4gYj3NbddSfSXdoYndrM5XfePDedIdx59pU/tDcfLpDE8eOLKfyM5OpX+JfvcPS8VR+a2833aGJnUHuPTfudNIdxsnfl+PxKN2hsdE4FW+3JukKnXauw6H5uXSHJp5wPPe+7fXyz93TnnhjKv8Nt+TyTS0v5T5rH149l+7w5fsfSuU3dwbpDk30ev1UPvdu+1utXLzTz39nTcOdPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQrrTXtjrTn3poxsl8xERk0kqvt+dz3doYHN3J5Vfu+eedIfZbm7nH7nxSekOTdx64xNS+fknz6U7jCatVP7PP/XpdIcm7l9dT+VHl+G3Ybude+5m+r10h6YOz+Y+s9KfmRGxMxyk8gtX6Om7fuVwKn/T8eV0h6fcelMqf82pfIcmHtlcTeU/cued6Q6ff+jBVH5nPEp3aKLf7aTy7VZuY0RE9JI7pXUZptI03PkDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAopDvthaPRKHVQJ5X+2w4xSeW3ulP/cy+rS7v7qfzC+QvpDjO9fip/5Nob0h2auOHE8VR+dm4h3eFTn7sjlb+wlv/7NbG5O0jl2638++XYkcVU/vRVx9IdmrrlupOp/NbGRrrDvfefSeXHe710hyaOLs6m8jdfk3vuIyKWTy2l8oNx7nO7qS/f/0Aqf9dDD6c7XNzdSeXHV+i+UieSO6WV2xgREb3kP33UzneYhjt/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFtCaTyeRKlwAA4PHhzh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAh3WkvfN53/WjqoJkYpPIREfuj3GP0WpN0hz/54G8dOPN9z//21JknztyXykdErCzM5Dp80zenO7zqV99z4Mwf/Pb7U2eO+v1UPiLijjvvTOUfOHsx3eHXf+UdB878k1e+PnXm3OxcKh8RcXz5UCp/8sSRdIfXv/rljXL/+l3vTp17x6c+ncpHRHz2r29P5RcXFtMdPvyxPztw5u1vflvqzBc99+tT+YiIxZNHU/l7z6+nO7z4xS88cObn3v3rqTO/ciHf+9zuMJW/uJPLR0T85XvedODM17367akzW738/bBWJ/cY4/bUs+yr+qtf/OnHvMadPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCulNf2W7lThpPcvmImOl3cg+Qr9DI2txsKr/X66U7XDx/LpXf/Nwd6Q5NPPjAvan8/PU3pjscO3kilV9cOpLu0MQzvyb3b5/r9dMd5mdmUvl+9j2fsL+zlcqvPvxQusPm2TOpfPfwbrpDExfPnU3lH7m0nu4w2tlM5T/xN59Pd3jxi1944Mxnb789debs8tFUPiLi9MqxXIf+frpDE732KJUfT3L5iIj+AWbVo5nJbq0pufMHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFBId9oLO61J6qD2ZZiZhw/Np/LdTidfosm5h5ZS+c2FQ+kOg/ULqXzvkYfSHZpY/co9qXzrxLXpDq1u7nUzP9dLd2hiaXE2lZ/t5nvPdHKP0epcud+nC/OLqfzRo8fTHS6t5B5j/gr9vt9Z20jl7z97Md3h7vvuTuU/+clPpDtEvPXAiTs/9bHUiU9/1jek8hERR4+tpPJ73dxeaGou+RXfauc3wnxyKx1u7ac7TMOdPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEK601547PBC6qBTKydT+YiIq69eSeVnZ2fSHZo4fTr3b7/rkXvTHYbJfGdnN92hib177kvlBzefS3cYLc+l8nOTK/Mba6bTS+V7vVw+IiI6yX97+8r9Pj1y7Ggq/9RnPTPd4dih5VR+cO5iukMT7Uknld8ZjdMdHnjw4VT+4fseSHdoYnBhNZVvr19Kdzh/512p/MMb2+kOTfQ3t1L5laUj6Q6z471Ufm6Q/baejjt/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFtCaTyeRKlwAA4PHhzh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHdaS/8xX/3O6mDbr7uqlQ+ImJuJpff2rqU7vDSl7zkwJk3vemNqTM//n/+NJWPiJjcd18qf3Orl+7w3gcO3uGnn/KM1Jknv/VbU/mIiPbXPimVn2nNpjv86Mt/8MCZ3/zt96fO7M/1U/mIiFYrl28PJ+kO3/M9L22Ue/9//UDq3K293VQ+ImL94noqP9zMd3jdW1574Mzb3vqO1JlHTp9K5SMiPvuJz6Tyn/noR9MdPv7XHzlw5gXPeV7qzNOn8s/dw2fOpfL3nL+Q7nDnXbcfOPP8Fx/8+/nvetbTn57KR0QcPTSfyq+eX013+OV3P/b7z50/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEK60174jc96euqguU4qHhER588/lMpffOThfIkG9tbXUvn9GKY7bMckld9qXYY/YAPd7Z3cA3zhznSH2etPpfK94/PpDk3M5v7ksZDMR0TMdKb+iHlU8/Mz+RINnT60lMqf7+b+7RERo+Rbv71yPN2hiauf+uRUftxppTvc/NSnpfKdSf7v18Stz/i6VH53/Vy6w+7uWirfGW+lOzRxcjH3PfWsp96Q7nDNqWtS+c987ovpDtNw5w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoJDutBdeWruYOuj87mYqHxGxvbmWyu9v76Y7NDHfnfppflRLhxfTHdbn51L51eGV+Z0w7HVS+daZM+kOva88nMofWlxJd2hieTzJ5bu9dIfFpdxrtz83n+7Q1NLSQio/aOee/4iIUbufyrc7M+kOTSzP5p67tWH+s/rE1cdT+eXF2XSHJp72rGem8ufuuyfdYX+Uy994GT47mnjB3/+2VP45X/+cdIejx4+m8oeO5fLTcucPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgkO60F374Y59IHXRoYSaVj4g4cXw5lT9ybCXdoYmrTh1L5be3T6c7dFq5/OaZi+kOTZyZzeVPHplLdzjcyj15R9uddIcmTiwfTuVXlhfSHVq93HO3sb+Z7tDU6uaFVH5jb5ju0O3Pp/KH+sk3UEP9vd1Ufvf82XSHmd4olT/Um/rr8bI6Ot9L5ReuuTbd4fChI6l8ezb/udvE6aty35V7O3vpDvtbW6n8zcmdMy13/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACmlNJpPJlS4BAMDjw50/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQrrTXviDP/bm1EGt8TCVj4h42tNuSeWfesOpdIcXvvjbD5z50O++L3XmA3fflcpHRJw/dzGXfySXj4h49+9/4MCZ17zo21JnPufmm1P5iIgnP/PZqfyRm25Md7jpBS84cOa+j38kdebW6plUPiJi7cEHU/nN9e10hxe+9nWNch/8pXelzt3p9FL5iIjWzGIqP9Pppzt856u+/8CZd7/xbakzzzz8SCofEXFsMXdv48jiTLrDD/7CwV9Dv/vmt6TObLXzf/PdXieV32/l7yu96i0/c+DMb9z2S6kz5+dmU/mIiCOL86n8od4k3eF5L/uhx7zGnT8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCutNeeGh5OXXQfffem8pHRKxvbKbyvX4/3aGJ5aUjqfx6fzbdoTU7l8pfe2Pu79/Ut3z9c1P5r3nG16Q7nLzpian8YKaT7tDEg6tnUvl7PvPpdIedux9M5Xub++kOTW186nOp/KCb/7tPujOp/IXxJN0hXvX9B47c8ZG/TB25ur6RykdEbB0/nMrvHllMd2jiwa/clcqPW710h0E3d19o1Lky95Xu/9IXk4+Qf89m/+XtVv4z73kv+6HHPid9CgAA/98w/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAAox/gAACjH+AAAKMf4AAArpTnvhk265JXXQ1vZOKh8R0et0UvnBZejQRGuYy89359MdJrPjVH7l+Il0hyZu/tpnpPIrN96Q7rDTm0nlz549k+5wdYPMmXPnU2eujZIv3IjYmZ36I+ZRjbZ30x2aun/rYio/3NtLd5hMcr/P967Q7/vzg61UfudQ/jNvdPRYKj8+ejjdoYnR0ZVUfm88SXfYneS+LybtVrpDE8OlxVS+P5vLR0R0Z/q5fD+3c6blzh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAh3WkvPH3t1amD1tfXUvmIiJOznVR+f2Mz3aGJ4c4glT9x8tp0h+4NC6n8zJGldIcmuidXUvmHNtfTHdY3d1P5zmic7tDE1Sdyr5tud+qPh6/q7JEjqfzaxUvpDk0Nbrgmld9ay3ff3dlP5YeTK/P7fvH6J6TyJ4+dSHe47tqrUvml2V66QxMnbnlKKj9qtdId9ia5z6xhMt/UySfdksovLB5Kd+jPzaTynU5u50zLnT8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEKMPwCAQow/AIBCjD8AgEJak8lkcqVLAADw+HDnDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoJDutBd+8I8/kjrozJlHUvmIiP7Weip/9DJM3X/88h84cOaT//NDqTOPnjyeykdE9BbmU/nN7e10hyc/+xsPnPnTD/1+6szzF9dS+YiI2ZnFVP7USv7v9+wX/sMDZ+7+5CdSZ971lS+l8hER9z90fyo/HrXSHV7+U69vlPsvv/Ke1LmjySSVj4jY2NpL5Tc3cvmIiDfd9pYDZ17/mn+ZOvP8zk4qHxGxsnI4le8M99Md3vGutx8488bXvTV15szcbCofEdGe7SUfIF0h/tXP/PSBMz/3zn+bOrPbnXoSfVUz/dxj9Hv5Dj/6qlc85jXu/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAU0p32wtZwL3XQeHcrlY+ImO93UvnT15xOd2ji1PVPSOVb/VG6w9rq2VT+7i99Pt3hyc/+xgNn7vz0R3OH9vq5fEScvPbGVP7chUG6QxODyL1noztOd9jcuJjKr61eSndo6qEH7k3lewvz6Q5b28NU/tz5jXSHJs6fzX3ePLKW771+YS2VH+9fmfft7bd/MZWfm8+/7nozvdwDtFvpDk3c+fkvp/K9br73oeT7fnF+Lt1hGu78AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAU0p32wslgkDrommMrqXxExMnDi6n84spSukMTg9FOKr/65bvTHe6/5wup/JkzD6Q7NDFYX03lZw8dSXe4dO6RVH7UvjK/sUaD3VR+cbaf7jA/l3uMs+29dIfGZ6+fTeU7G1N/vH5Vk/1OKn/xwka6QxNr6xdT+dakle4w3Mu9/mM8SXdoYn8wSuUnk9z3TUREdy/3fd/p5F/7TYx39lP57qG5dIfWOPfa3d16fD7z3PkDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAopDvthdeePJk6aK6X35n33/vFVP7suXvSHW5+xjMOnPns7R9Jnbm1+kgqHxGxvXEx9wDjYbpDE93+1C/RR9Xv9dMdVg4fSeVn5hfTHZqYa8+l8p25o+kORw8vp/LnL6ymOzTVaeXyrcE43aE7zr3+Z9q9dIcmRqNJKj8Y7KU7jCP7mXVl7o0MxqNUfrife+4jInrj3GP0+8k3T0OTVu7cbi/3fouImLRzHXYH++kO03DnDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgEOMPAKAQ4w8AoBDjDwCgkNZkMplc6RIAADw+3PkDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAoxPgDACjE+AMAKMT4AwAopDvthXd89kupgwZr51P5iIjbb/9YKr+7ke/wyte//cCZX7vtJ1Nntib7qXxERGc8SeXHO4N0h1fd9h8PnPn3b3pF6sz+7EIqHxGxtHwylT95zfXpDs9/yT8/cObOj30kdWa31UvlIyK+cvcdqfzf3PE36Q6vfdu7muVe+QOpc4d7ufdcRETst1Lx9cEoXeE3P/A7B858x7d/d+rMra3tVD4iotfPvX4Ho9xzHxHxJ3/6hwfOPO9bviN1ZqfbSeUjIjqd3GN0k/mIiP/9v95/4Mx3/9OXp848dvRQKh8R0c2+7nbz37Xve+8vP+Y17vwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAUYvwBABRi/AEAFGL8AQAU0p32ws/d9aXUQUudQSofETE3O3XdR8/PHE13aOLwkWOp/NalC+kO+3vbqXy71Up3aKI1maTy+3ub6Q4PPZR77i5u7aQ7PL9BZn3zUurMhbmlVD4iYnM792+/tJF77jPWNvdS+b293Gs3IqLXzv0+77Q76Q5NzCZvK4y7+d6t5L99eyf/ndXEcDhM5dud/D2d4Xicyg9GuXxT2zu7qfz+/ly6Q7+be/6z+Wm58wcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUIjxBwBQiPEHAFCI8QcAUEh32gs3t9ZTB3Xag1Q+ImIw2E/lr7rqVLpDE0+59Zmp/MVzZ9IdHrzny6n81qW1dIcmWp2pX6KPajzOvWYiIgaDvVT+4a/knvum7rk3d+7NNzwx3WEw2EnlNze30h2aWr2Q+8wbTDrpDkvz86n8THuS7tBEv5d737aile4wbuc6bO+N0h2aaMU4lR+N870nk9zrZjzJ//2aGI5yz91gL/990Wvn7ql12o/Pc+fOHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHdaS+86frrUgddfPCuVD4iYnZ+PpU/dc3pdIcmbnjCLan8VaeuTXc4tnIilX/g/rvTHZroLx5O5S+unk93GE9aqfzO7na6QxNf+MIdqfzCXC/dodfP/b5cWFxId2iq28v9+/dHl+G3daeTiu/u7eY7NDAaT3IP0M695yIiopXr0G4n/w0N9fu5v3mnN/XX+le1Oxil8qPRON2h2bm5v9nO7iDdYTzMPXedx+mWnDt/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFGH8AAIUYfwAAhRh/AACFtCaTyeRKlwAA4PHhzh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAhxh8AQCHGHwBAIcYfAEAh/w+UEEeeFTtiIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_patches(patches[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomTransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.norm1(x)\n",
    "        attn_output, _ = self.attention(y, y, y)\n",
    "        x = x + attn_output\n",
    "        \n",
    "        x = x + self.mlp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VisualTransformer(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, embed_dim=256, num_classes=10, depth=6, num_heads=8, mlp_dim=512, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        # Patch Embedding\n",
    "        self.patch_embedding = nn.Linear(patch_size * patch_size * 3, embed_dim)\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))\n",
    "\n",
    "        # Class Token\n",
    "        self.class_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "\n",
    "        # Dropout\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.transformer = nn.ModuleList([\n",
    "            CustomTransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        # Output layers\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.mlp_head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Divide image into patches\n",
    "        patches = image_to_patches(x, self.patch_size).flatten(2)  # Assume image_to_patches is implemented\n",
    "        embeddings = self.patch_embedding(patches)\n",
    "\n",
    "        # Add class token and positional embeddings\n",
    "        cls_token = self.class_token.expand(batch_size, -1, -1)\n",
    "        embeddings = torch.cat([cls_token, embeddings], dim=1) + self.positional_embedding\n",
    "\n",
    "        # Apply dropout after embeddings\n",
    "        embeddings = self.embedding_dropout(embeddings)\n",
    "\n",
    "        # Pass through Transformer layers\n",
    "        for layer in self.transformer:\n",
    "            embeddings = layer(embeddings)\n",
    "\n",
    "        # Classification based on the class token\n",
    "        cls_output = self.layer_norm(embeddings[:, 0])\n",
    "        return self.mlp_head(cls_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visual_transformer_graph.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# Instantiate the model\n",
    "model = VisualTransformer(img_size=32, patch_size=4, embed_dim=256, num_classes=10)\n",
    "\n",
    "# Dummy input tensor (batch size 1, 3 channels, 32x32 image)\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# Forward pass and graph visualization\n",
    "output = model(dummy_input)\n",
    "graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "# Save or display the graph\n",
    "graph.render(\"visual_transformer_graph\", format=\"png\", cleanup=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = VisualTransformer().to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "for epoch in range(160):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1} completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
